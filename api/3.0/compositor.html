<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>OGRE-Next: Compositor</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="ogre_style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="ogre-logo.png"/></td>
  <td id="projectalign">
   <div id="projectname">OGRE-Next<span id="projectnumber">&#160;3.0.0</span>
   </div>
   <div id="projectbrief">Object-Oriented Graphics Rendering Engine</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('compositor.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Compositor</div></div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#CompositorNodes">Nodes</a><ul><li class="level2"><a href="#CompositorNodesChannelsAndRTTs">Input &amp; output channels and RTTs</a><ul><li class="level3"><a href="#CompositorNodesChannelsAndRTTsLocalTextures">Locally declared textures</a></li>
<li class="level3"><a href="#CompositorNodesChannelsAndRTTsFromInputChannel">It comes from an input channel</a></li>
<li class="level3"><a href="#CompositorNodesChannelsAndRTTsGlobal">It is a global texture</a></li>
<li class="level3"><a href="#CompositorNodesChannelsAndRTTsMainRenderTarget">Main RenderTarget</a></li>
</ul>
</li>
<li class="level2"><a href="#CompositorNodesTarget">Target</a></li>
<li class="level2"><a href="#CompositorNodesPasses">Passes</a><ul><li class="level3"><a href="#CompositorNodesPassesClear">clear</a></li>
<li class="level3"><a href="#CompositorNodesPassesGenerateMipmaps">generate_mipmaps</a></li>
<li class="level3"><a href="#CompositorNodesPassesQuad">quad</a></li>
<li class="level3"><a href="#CompositorNodesPassesResolve">resolve</a></li>
<li class="level3"><a href="#CompositorNodesPassesRenderScene">render_scene</a></li>
<li class="level3"><a href="#CompositorNodesPassesShadows">shadows</a></li>
<li class="level3"><a href="#CompositorNodesPassesStencil">stencil</a></li>
<li class="level3"><a href="#CompositorNodesPassesUavQueue">uav_queue</a><ul><li class="level4"><a href="#CompositorNodesPassesUavQueueSync">Synchronization</a></li>
</ul>
</li>
<li class="level3"><a href="#CompositorNodesPassesCompute">compute</a></li>
</ul>
</li>
<li class="level2"><a href="#CompositorNodesTextures">Textures</a><ul><li class="level3"><a href="#CompositorNodesTexturesMsaa">MSAA: Explicit vs Implicit resolves</a><ul><li class="level4"><a href="#CompositorNodesTexturesMsaaImplicit">Implicit resolves</a></li>
<li class="level4"><a href="#CompositorNodesTexturesMsaaExplicit">Explicit resolves</a></li>
<li class="level4"><a href="#CompositorNodesTexturesMsaaResources">Resources</a></li>
</ul>
</li>
<li class="level3"><a href="#CompositorNodesTexturesDepth">Depth Textures</a></li>
</ul>
</li>
</ul>
</li>
<li class="level1"><a href="#CompositorShadowNodes">Shadow Nodes</a><ul><li class="level2"><a href="#CompositorShadowNodesSetup">Setting up shadow nodes</a></li>
<li class="level2"><a href="#CompositorShadowNodesExample">Example</a></li>
<li class="level2"><a href="#CompositorShadowNodesAtlasAndPointLights">Shadow map atlas &amp; Point Lights</a></li>
<li class="level2"><a href="#CompositorShadowNodesReuseEtc">Reuse, recalculate and first</a></li>
<li class="level2"><a href="#CompositorShadowNodesTypes">Shadow mapping setup types</a><ul><li class="level3"><a href="#CompositorShadowNodesTypesUniform">Uniform shadow mapping</a></li>
<li class="level3"><a href="#CompositorShadowNodesTypesFocused">Focused</a></li>
<li class="level3"><a href="#CompositorShadowNodesTypesPssm">PSSM / CSM</a></li>
<li class="level3"><a href="#CompositorShadowNodesTypesPlaneOptimal">Plane Optimal</a></li>
</ul>
</li>
<li class="level2"><a href="#CompositorShadowNodesShaders">Writing shaders</a></li>
</ul>
</li>
<li class="level1"><a href="#CompositorWorkspaces">Workspaces</a><ul><li class="level2"><a href="#CompositorWorkspacesDataDependencies">Data dependencies between nodes and circular dependencies</a></li>
</ul>
</li>
<li class="level1"><a href="#CompositorSetupCode">Setting up code</a><ul><li class="level2"><a href="#CompositorWorkspacesSetupInitialize">Initializing the workspace</a></li>
<li class="level2"><a href="#CompositorWorkspacesSetupSimple">Simple bootstrap for beginners</a></li>
<li class="level2"><a href="#CompositorWorkspacesSetupAdvanced">Advanced C++ users</a></li>
</ul>
</li>
<li class="level1"><a href="#StereoAndSplitScreenRendering">Stereo and Split-Screen Rendering</a><ul><li class="level2"><a href="#CompositorWorkspacesStereoPerWorkspace">Per-Workspace offset and scale</a></li>
<li class="level2"><a href="#CompositorWorkspacesStereoViewportMask">Viewport modifier mask</a></li>
<li class="level2"><a href="#CompositorWorkspacesStereoExecutionMask">Execution mask</a></li>
<li class="level2"><a href="#CompositorWorkspacesStereoDefaultValues">Default values</a></li>
</ul>
</li>
<li class="level1"><a href="#autotoc_md95">Advanced MSAA</a><ul><li class="level2"><a href="#autotoc_md96">What is MSAA?</a><ul><li class="level3"><a href="#autotoc_md97">Supersampling Antialiasing (SSAA) vs MSAA</a></li>
<li class="level3"><a href="#autotoc_md98">MSAA approach to the problem</a></li>
</ul>
</li>
<li class="level2"><a href="#autotoc_md99">Ogre + MSAA with Implicit Resolves</a></li>
<li class="level2"><a href="#autotoc_md100">Ogre + MSAA with Explicit Resolves</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><p>The Compositor is a Core and key component in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.0. In 1.x, it was just used for fancy post-processing effects. In 2.0, it's the way to tell <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> how you want to render the scene. Without setting it up, <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> won't render to screen.</p>
<p>With the Compositor, the user stops having to deal with setting Viewports, RenderTargets, updating these RenderTargets every frame, etc.</p>
<p>Instead the user has now to setup Nodes and a Workspace. The workspace is the top level system where the user indicates which Nodes he wants to use, how they will be connected, which global render textures will be declared (which can be seen by all nodes from the same workspace), where to render the final output (i.e. RenderWindow, an offscreen RenderTexture) and which SceneManager to use. The user can have multiple workspaces active at the same time.</p>
<p>The new Compositor system was heavily inspired by Blender's Compositor system. Picture from Blender:</p>
<div class="image">
<img src="workspace.png" alt=""/>
</div>
    <div class="image">
<img src="node.png" alt=""/>
</div>
    <p>Compositor script syntax hasn't changed much, which should make porting them quite easy. Internally though, the new system was written from scratch (while reusing &amp; reviewing some of the existing code); as the previous Compositor was stack-based, while the new one is node-based.</p>
<p>So, if you used to manipulate the Compositor directly from C++; porting efforts could be considerably bigger.</p>
<h1><a class="anchor" id="CompositorNodes"></a>
Nodes</h1>
<p>A compositor node most likely resembles what used to be "a compositor" in 1.x</p>
<p>The following node clears the RT and draws everything that is in the render queue #50</p>
<div class="fragment"><div class="line">compositor_node MyNode</div>
<div class="line">{</div>
<div class="line">    in 0 Input_as_MyLocaName <span class="comment">// Take input texture #0 and use the local name &quot;Input_as_MyLocaName&quot; for reference</span></div>
<div class="line">    </div>
<div class="line">    target Input_as_MyLocaName</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">//Clear to violet</span></div>
<div class="line">        pass clear</div>
<div class="line">        {</div>
<div class="line">            colour_value 1 0 1 1</div>
<div class="line">        }</div>
<div class="line">        pass render_scene</div>
<div class="line">        {</div>
<div class="line">            visibility_mask 0xffffffff   <span class="comment">//Viewport&#39;s visibility mask</span></div>
<div class="line"> </div>
<div class="line">            rq_first        50      <span class="comment">//Inclusive</span></div>
<div class="line">            rq_last     51      <span class="comment">//Not inclusive</span></div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    out 0 Input_as_MyLocaName</div>
<div class="line">}</div>
</div><!-- fragment --><p>Where is <code>Input_as_MyLocaName</code> defined? What is its resolution? Its bit depth? The RT comes from the input channel, so the answer is that it depends on how the Workspace will connect this node. The Workspace may pass a local RTT declared in a previous node or it could pass RenderWindow.</p>
<h2><a class="anchor" id="CompositorNodesChannelsAndRTTs"></a>
Input &amp; output channels and RTTs</h2>
<p>A node's RT may come from three different sources:</p>
<ol type="1">
<li>It was locally declared.</li>
<li>It comes from an input channel.</li>
<li>It is a global texture declared in the Workspace. Global textures must use the <em><b>global_</b></em> prefix</li>
</ol>
<h3><a class="anchor" id="CompositorNodesChannelsAndRTTsLocalTextures"></a>
Locally declared textures</h3>
<p>The following script declares a local texture of resolution 800x600, clears it to violet, and puts it in the output channel #0 (so other compositor nodes can use it as input):</p>
<div class="fragment"><div class="line">compositor_node MyNode</div>
<div class="line">{</div>
<div class="line">    texture rt0 800 600 PF_R8G8B8</div>
<div class="line">    </div>
<div class="line">    target Input_as_MyLocaName</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">//Clear to violet</span></div>
<div class="line">        pass clear</div>
<div class="line">        {</div>
<div class="line">            colour_value 1 0 1 1</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    out 0 rt0</div>
<div class="line">}</div>
</div><!-- fragment --><p>You may have noticed the syntax for declaring the RTT is <b>almost exactly the same</b> as it was in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x</p>
<p>Refer to <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a>'s 1.9 documentation for more information about it.</p>
<p>There are a couple of small changes:</p>
<ul>
<li><b>New parameter</b> <code>no_gamma</code>: In 1.x HW gamma would be on by default if the global gamma settings were on; with no way to turn it off. But it could be forced always on using the keyword <code>gamma</code>. In <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.x, leaving the option blank uses the system's settings, writing the keyword <code>gamma</code> forces it on, and using the keyword <code>no_gamma</code> turns it off.</li>
<li>The parameter "scope" is no longer available.</li>
<li>The parameter "pooled" is no longer available.</li>
</ul>
<h3><a class="anchor" id="CompositorNodesChannelsAndRTTsFromInputChannel"></a>
It comes from an input channel</h3>
<p>Input channels are numbered. An input channel must be given a name so that they can be referenced locally at node scope by all target passes. There can't be any gaps (i.e. use channels 0 &amp; 2 but not 1)</p>
<p>Output channels are also numbered and can be assigned an RTT. This number will be later used by the Workspace to perform the connections.</p>
<p>The workspace will be responsible for connecting node A's output channels with node B's input channels. In <b>other words, channels are a way to send, receive and share RTTs between nodes.</b></p>
<p>The only restriction is that global textures can't be used neither as input or output (global textures are referenced directly). There can be more input channels than output channels, viceversa, and there may be no input nor output channels (i.e. when working with global textures alone).</p>
<p>The following (rather useless) snippet takes channel #0 and sends it to output channel #1, takes input channel #1 and sends it through output channel #0 (in other words it flips the channels), and also sends an uninitialized texture created locally to channel #2:</p>
<div class="fragment"><div class="line">compositor_node MyNode</div>
<div class="line">{</div>
<div class="line">    in 0 myFirstInput</div>
<div class="line">    in 1 mySecondInput</div>
<div class="line">    </div>
<div class="line">    texture rt0 target_width_scaled 0.25 target_height_scaled 0.25 PF_R8G8B8</div>
<div class="line"> </div>
<div class="line">    out 0 mySecondInput</div>
<div class="line">    out 1 myFirstInput</div>
<div class="line">    out 2 rt0</div>
<div class="line">}</div>
</div><!-- fragment --><p>Drawing inspiration from Blender's compositor system, the little dots on the left would be the input channels, while the dots on right would be the output texture channels:</p>
<div class="image">
<img src="channels.png" alt=""/>
</div>
    <h3><a class="anchor" id="CompositorNodesChannelsAndRTTsGlobal"></a>
It is a global texture</h3>
<p>Global textures are declared at workspace scope and have the same syntax as local textures (which is the same <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x's syntax). There are a few restrictions:</p>
<ol type="1">
<li>Global texture names must contain the <em><b>global_</b></em> prefix. Inversely, any local texture or input channel trying to use a name that starts with <code>global_</code> is illegal.</li>
<li>They can't be used in input or output channels.</li>
<li>Global textures can be seen by any node belonging to the same workspace, but they can't see a global texture that belongs to a different workspace.</li>
<li>If a Node uses a global texture that the Workspace didn't declare, execution of the workspace will fail.</li>
</ol>
<p>Global textures are as powerful/dangerous as global variables are in C++. The main reason of their existence is that many nodes may use temporary rtts to perform their work, and it's <em>very</em> wasteful to declare these intermediate rtts on every node when they can be shared and reused.</p>
<p>Sharing and reusage can also be achieved through input &amp; output channels, however for temporary rtts (or rtts that are accessed very frequently, i.e. a deferred shader's G Buffer) it would lead to connection hell; and hence global textures are a much better fit.</p>
<ul>
<li>in &lt;channel_id&gt;; &lt;local_texture_name&gt;;</li>
</ul>
<p>channel_id is a number in range [0; inf) but must be consecutive and continuous (no gaps, i.e. define channel 0, 2, but not 1). loca_texture_name cannot start with <code>global_</code>. A node definition may have no input.</p>
<ul>
<li>out &lt;channel_id&gt;; &lt;local_texture_name&gt;;</li>
</ul>
<p>channel_id is a number in range [0; inf) but must be consecutive and continuous (no gaps, i.e. define channel 0, 2, but not 1). loca_texture_name cannot start with <code>global_</code>. A node definition may have no output.</p>
<ul>
<li>in_buffer &lt;channel_id&gt;; &lt;buffer_name&gt;;</li>
</ul>
<p>For UAV buffers. Same as with regular textures, except you can reference global buffers, and global buffers don't have to start with <code>global_</code>. If a local buffer and a global buffer have the same name, the local buffer takes precedence.</p>
<ul>
<li>out_buffer &lt;channel_id&gt;; &lt;buffer_name&gt;;</li>
</ul>
<p>For UAV buffer connections. See <code>in_buffer</code>.</p>
<ul>
<li>custom_id &lt;string&gt;;</li>
</ul>
<p>Custom string that will be hashed to identify this Node definition. Useful for classifying nodes into categories.</p>
<h3><a class="anchor" id="CompositorNodesChannelsAndRTTsMainRenderTarget"></a>
Main RenderTarget</h3>
<p>When creating the Workspace instance, the C++ code will ask for the RT which should be the ultimate target (i.e. the RenderWindow). This RT is very important as keywords like <code>target_width_scaled</code> and settings like fsaa &amp; hw gamma will be based on the attributes from this main RT. This feature will be seen in more detail in the Workspace section.</p>
<blockquote class="doxtable">
<p>&zwj; Attention #1!</p>
<p>By default you cannot use the main RenderTarget as a texture (because it's usually the RenderWindow and D3D and OpenGL don't allow it), and doing it may result in a crash.</p>
<p>It is possible to manually call <code>node-&gt;connectFinalRT</code> and supply a texture pointer (i.e. if the final RenderTarget is a RenderTexture) that can be bound. An automated way of doing this is not yet implemented. </p>
</blockquote>
<h2><a class="anchor" id="CompositorNodesTarget"></a>
Target</h2>
<p>Targets include multiple passes. Their main purpose is define to which RenderTarget the passes will render to.</p>
<p>What's worth noting is that targets accept an optional parameter '<em>slice</em>'.</p>
<p>The slice parameter is optional and refers to which slice or face from a 3D texture (or cubemap or 2D array) to use from the given texture. Valid values can be numeric or the hint '+X'. '-X', '+Y', '-Y', '+Z', and '-Z'.</p>
<p>Note: The word 'slice' must not be written. Just write 'target myTexture +X' to work.</p>
<p>Note: When the target is a 3D/Cubemap/array texture, if the slice goes out of bounds, an exception will be raised. If the target is a 2D or 1D texture, this value is silently ignored. Default: slice = 0</p>
<p>At the moment there is only one setting:</p>
<ul>
<li>target_level_barrier [yes|no];</li>
</ul>
<p>Default value is no.</p>
<p>When yes, this setting is meant to be used with <code>skip_load_store_semantics</code> for optimization on mobile/TBDR targets, but should be used with care.</p>
<p><code>skip_load_store_semantics</code> allows <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> to execute multiple consecutive passes as if they were only one.</p>
<p>An obstacle for this is that barriers from all theses passes mut be issued <em>before</em> the first pass executes; otherwise the passes need to be internally broken up and <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> will complain if <code>skip_load_store_semantics on</code> but we can't merge the passes.</p>
<p><code>target_level_barrier yes</code> means that an extra hidden pass will be inserted at the beginning of the target and issue all necessary barriers from subsequent passes:</p>
<div class="fragment"><div class="line">target rt_renderwindow</div>
<div class="line">{</div>
<div class="line">    <span class="comment">// By having this set to true or yes, a barrier will be issued</span></div>
<div class="line">    <span class="comment">// to cover all 4 passes in this target, which happens</span></div>
<div class="line">    <span class="comment">// before the first render_quad</span></div>
<div class="line">    target_level_barrier <span class="keyword">true</span></div>
<div class="line"> </div>
<div class="line">    pass render_quad</div>
<div class="line">    {</div>
<div class="line">        load</div>
<div class="line">        {</div>
<div class="line">            all     dont_care</div>
<div class="line">        }</div>
<div class="line">        store</div>
<div class="line">        {</div>
<div class="line">            all     dont_care</div>
<div class="line">            colour  store</div>
<div class="line">        }</div>
<div class="line"> </div>
<div class="line">        material MyMaterial</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    pass render_scene</div>
<div class="line">    {</div>
<div class="line">        skip_load_store_semantics <span class="keyword">true</span></div>
<div class="line"> </div>
<div class="line">        rq_first    0</div>
<div class="line">        rq_last     5</div>
<div class="line"> </div>
<div class="line">        shadows     MainCharacter reuse</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    pass render_quad</div>
<div class="line">    {</div>
<div class="line">        skip_load_store_semantics <span class="keyword">true</span></div>
<div class="line">        material <a class="code hl_enumvalue" href="namespace_ogre_1_1_texture_source_type.html#a487889f4cfc926c4eaaf01e2f4e68c5aa602ee38ea2347d313beab4dabced99fb">Compositor</a>/UpsampleDepth</div>
<div class="line">        input 0 worldRt_depth</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    pass render_scene</div>
<div class="line">    {</div>
<div class="line">        skip_load_store_semantics <span class="keyword">true</span></div>
<div class="line"> </div>
<div class="line">        rq_first    14</div>
<div class="line">        rq_last     249</div>
<div class="line"> </div>
<div class="line">        shadows     NormalShadows reuse</div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="ttc" id="anamespace_ogre_1_1_texture_source_type_html_a487889f4cfc926c4eaaf01e2f4e68c5aa602ee38ea2347d313beab4dabced99fb"><div class="ttname"><a href="namespace_ogre_1_1_texture_source_type.html#a487889f4cfc926c4eaaf01e2f4e68c5aa602ee38ea2347d313beab4dabced99fb">Ogre::TextureSourceType::Compositor</a></div><div class="ttdeci">@ Compositor</div><div class="ttdoc">Created by compositor.</div><div class="ttdef"><b>Definition</b> OgreTextureGpu.h:181</div></div>
</div><!-- fragment --><p><b>Note that not always <code>target_level_barrier yes</code> can be successful.</b></p>
<p>For example if pass <code>A</code> needs texture <code>X</code> to be in state <code>Texture</code> for sampling but pass <code>C</code> needs that same texture in state <code>Uav</code> then we have a contradiction as we can't transition to two states at the same time.</p>
<p>The only solution is to break up the passes and issue two barriers. Note that you can however issue break ups manually:</p>
<div class="fragment"><div class="line">target rt_renderwindow</div>
<div class="line">{</div>
<div class="line">    target_level_barrier <span class="keyword">true</span></div>
<div class="line">    <span class="comment">// Pass A</span></div>
<div class="line">    pass render_quad {}</div>
<div class="line">    <span class="comment">// Pass B</span></div>
<div class="line">    pass render_quad {skip_load_store_semantics <span class="keyword">true</span>}</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">target rt_renderwindow</div>
<div class="line">{</div>
<div class="line">    target_level_barrier <span class="keyword">true</span></div>
<div class="line">    <span class="comment">// Pass C</span></div>
<div class="line">    pass render_quad {}</div>
<div class="line">    <span class="comment">// Pass D</span></div>
<div class="line">    pass render_quad {skip_load_store_semantics <span class="keyword">true</span>}</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="CompositorNodesPasses"></a>
Passes</h2>
<p>Passes are the same as they were in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x. At the time of writing there are 10 types of passes:</p>
<ul>
<li>clear (PASS_CLEAR)</li>
<li>generate_mipmaps (PASS_MIPMAP)</li>
<li>quad (PASS_QUAD)</li>
<li>resolve (PASS_RESOLVE)</li>
<li>render_scene (PASS_SCENE)</li>
<li>shadows (PASS_SHADOWS)</li>
<li>stencil (PASS_STENCIL)</li>
<li>uav_queue (PASS_UAV)</li>
<li>compute (PASS_COMPUTE)</li>
<li>custom (PASS_CUSTOM)</li>
</ul>
<p>More passes are planned including the ability for users to extend with custom passes which used to be present in 1.x.</p>
<p>Planned passes are:</p>
<ul>
<li>Paraboloid mapping passes (useful for efficient env. mapping and point light shadow maps)</li>
<li>N pass (optimizes <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> data for two or more passes i.e. a Z pre-pass with minimum overhead in the engine since the cull data is the same)</li>
</ul>
<p>All passes support the following script parameters:</p>
<ul>
<li>pass &lt;type&gt;; [customId]</li>
</ul>
<p>'<em>type</em>' must be one of the supported types: clear, quad, resolve, render_scene, stencil, custom.</p>
<p>The <em>customId</em> parameter is optional and is used by custom passes to give the registered custom pass provider the means to identify multiple types, in case there are more than one type of custom passes.</p>
<ul>
<li>num_initial &lt;number&gt;;</li>
</ul>
<p>Number of times this will be executed. Default is -1, which means always execute. When the execution count hits that value, it won't executed again until a d3d device reset, resize or workspace recreation (the execution count is reset and executed N times again)</p>
<p>This parameter replaces the <code>only_initial</code> parameter in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x.</p>
<ul>
<li>flush_command_buffers &lt;off|on&gt;;</li>
</ul>
<p>Whether to flush the command buffer at the end of the pass. This can incur in a performance overhead (see OpenGL's glFlush and D3D11' ID3D11DeviceContext::Flush) for info. Usually you want to leave this off. However for VR applications that must meet VSync, profiling may show your workload benefits from submitting earlier so the GPU can start right away executing rendering commands.</p>
<p>The main reason to use this is in CPU-bound scenarios where the GPU starts too late after sitting idle.</p>
<ul>
<li>identifier &lt;number&gt;;</li>
</ul>
<p>An arbitrary user-defined numeric ID used for identifying individual passes in the C++ code.</p>
<ul>
<li>execution_mask &lt;hex number&gt;;</li>
</ul>
<p>8-bit hex value. Specifies the execution mask. For more information see Stereo and Split-Screen Rendering for more information. Default is 0xFF except for clear passes, which default to 0x01.</p>
<ul>
<li>viewport_modifier_mask &lt;hex number&gt;;</li>
</ul>
<p>8-bit hex value. Specifies the viewport modifier mask. For more information see Stereo and Split-Screen Rendering for more information. Default is 0xFF except for clear passes, which default to 0x00.</p>
<ul>
<li>colour_write &lt;off|on&gt;;</li>
</ul>
<p>Disables colour writes. Useful for Z prepass passes; or pixel shaders that output to an UAV instead of a regular RenderTarget (like a Render Texture).</p>
<p>Default: on.</p>
<ul>
<li>profiling_id "name";</li>
</ul>
<p>User defined text for identifying this pass by name in profilers and GPU debuggers</p>
<h3><a class="anchor" id="CompositorNodesPassesClear"></a>
clear</h3>
<p>The syntax for clear passes is the same as 1.x; except that by default now Stencil is also cleared. This follows performance reasons, as GPU architectures where the Z buffer is tied with the stencil buffer, clearing only the Z buffer hinders the driver from discarding the buffer entirely or using fast Z clears.</p>
<h3><a class="anchor" id="CompositorNodesPassesGenerateMipmaps"></a>
generate_mipmaps</h3>
<p>Generate_mipmaps doesn't have special parameters other than the shared ones that are still relevant (i.e. identifier). They're useful for explicitly populating the lower mip levels after you've done rendering.</p>
<p>This pass does not require the <em>automipmap</em> keyword when declaring the textures. The 'automipmaps' option allows you to skip using generate_mipmaps entirely. It can be tempting, but the problem with this option is that if you write and read to/from the texture several times but only want to genrate mipmaps after the whole process is over, the automipmap keyword will generate mipmaps every time the texture needs to be read again after it was being tagged as dirty for having written to it.</p>
<p>Disabling automipmap and using generate_mipmaps instead allows you to explicitly control when the mipmaps are generated; without hidden surprises eating GPU performance away.</p>
<ul>
<li>mipmap_method [api_default|compute|compute_hq]</li>
</ul>
<p>Default is <code>api_default</code> which will ask the API or driver to generate them for you. If the API does not support it (e.g. DX12) then Compute will be used.</p>
<p><code>compute</code> (Experimental) uses a compute shader. Compute requires the texture to be UAV. Some formats may not work, such as sRGB formats, therefore textures have to use no_gamma modifier.</p>
<p><code>compute_hq</code> (Experimental) uses a high quality gaussian filter. Useful for fast &amp; high quality mipmap generation.</p>
<ul>
<li>kernel_radius &lt;8&gt;;</li>
</ul>
<p>Integer value. Default is 8. Must be positive, even number. Defines the kernel radius of the compute gaussian filter.</p>
<ul>
<li>gauss_deviation &lt;0,5&gt;;</li>
</ul>
<p>The standard deviation of the gaussian filter. The default is 0,5.</p>
<blockquote class="doxtable">
<p>&zwj; Attention #1!</p>
<p>generate_mipmaps works at texture level. If you pass a Cubemap, it will generate mipmaps for all the faces. If you pass a 3D or a 2D array texture, it will generate mipmaps for all slices.</p>
<p>A RenderWindow does not have a texture, thus attempting to generate mipmaps on it will raise an exception.</p>
<p>Attention #2!</p>
<p>In order for compute-based mipmap generation to work, <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> must be compiled with JSON support, and the user must include the resources included in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a>'s repository at Samples/Media/2.0/scripts/materials/Common </p>
</blockquote>
<h3><a class="anchor" id="CompositorNodesPassesQuad"></a>
quad</h3>
<p>Quad passes have the same syntax as 1.x; plus the following keywords have been added:</p>
<ul>
<li>use_quad [yes|no]</li>
</ul>
<p>Default is <em>no</em>. When <em>no</em>; the compositor will draw a fullscreen <em>triangle</em>. Due to how modern GPUs work, using two rectangles wastes GPU processing power in the diagonal borders because pixels are processed <em>at least</em> in 2x2 blocks; and the results from the pixels out of the triangle have to be discarded. A single triangle is more efficient as all blocks are fill the viewport area, and when the rectangle goes out of the viewport, the gpu efficiently clips it.</p>
<p>When the viewport is not <code>0 0 1 1</code>; this value is forced to <em>yes</em>. The following picture illustrates a fullscreen triangle:</p>
<div class="image">
<img src="use_quad.png" alt=""/>
</div>
    <p>Interpolation will cause that the effective UV coordinates will be in the [0; 1] range while inside the viewport area.</p>
<p>Using <code>camera_far_corners_world_space</code> will also force to use a quad instead of a tri (but <code>camera_far_corners_view_space</code> works with tris)</p>
<p>For an explanation of why this is a performance optimization, refer to <a href="http://fgiesen.wordpress.com/2013/02/10/optimizing-the-basic-rasterizer/">Optimizing the basic rasterizer</a> by Fabien Giesen.</p>
<ul>
<li>expose &lt;textureName&gt;;</li>
</ul>
<p>Low level materials can access local and global textures via the old 'content_type compositor' setting, and Hlms materials can access them by calling <code>SceneManager::getCompositorTextures</code>. But before you can do that, you need to expose them to the pass. This is necessary so <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> can know which textures may or will be used during the pass so resource transitions and barriers can be issued in explicit APIs like DX12 and Vulkan.</p>
<ul>
<li>skip_load_store_semantics [yes|no];</li>
</ul>
<p>When yes, the load and store semantics will be ignored. Use with care as improper usage may lead to rendering bugs or crashes.</p>
<p>Normally <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> tries to merge passes when possible but certain advanced uses are impossible or difficult to get automatically merged, thus this flag indicates we want e.g.</p>
<div class="fragment"><div class="line">compositor_node MyNode</div>
<div class="line">{</div>
<div class="line">    in 0 rtt</div>
<div class="line"> </div>
<div class="line">    target rtt</div>
<div class="line">    {</div>
<div class="line">        pass render_quad</div>
<div class="line">        {</div>
<div class="line">            load</div>
<div class="line">            {</div>
<div class="line">                <span class="comment">// Do not load or clear anything to colour, this pass will overwrite everything</span></div>
<div class="line">                all     clear</div>
<div class="line">                colour  dont_care</div>
<div class="line">            }</div>
<div class="line">            store</div>
<div class="line">            {</div>
<div class="line">                <span class="comment">// Only save colour, don&#39;t care about depth/stencil</span></div>
<div class="line">                all     dont_care</div>
<div class="line">                colour  store</div>
<div class="line">            }</div>
<div class="line"> </div>
<div class="line">            material MaterialThatWritesToEveryColourPixel</div>
<div class="line">        }</div>
<div class="line"> </div>
<div class="line">        pass render_scene</div>
<div class="line">        {</div>
<div class="line">            <span class="comment">// Inherit the same semantics of the previous pass</span></div>
<div class="line">            skip_load_store_semantics <span class="keyword">true</span></div>
<div class="line"> </div>
<div class="line">            rq_first 0</div>
<div class="line">            rq_last max</div>
<div class="line"> </div>
<div class="line">            <span class="comment">// We can NOT use recalculate or first, because</span></div>
<div class="line">            <span class="comment">// doing so will end the pass, and we&#39;re explicitly</span></div>
<div class="line">            <span class="comment">// asking Ogre to not close the pass.</span></div>
<div class="line">            shadows     MyShadowNode reuse</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>The reason you should be careful is that we assume you know where you're drawing. Consider the following example:</p>
<div class="fragment"><div class="line">target TargetA</div>
<div class="line">{</div>
<div class="line">    pass render_quad {}</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">target UnrelatedTargetB</div>
<div class="line">{</div>
<div class="line">    pass render_quad { skip_load_store_semantics <span class="keyword">true</span> }</div>
<div class="line">}</div>
</div><!-- fragment --><p>This script will <em>not</em> behave as expected because <b>both render_quad passes will draw to TargetA!</b></p>
<p>This is because with <code>skip_load_store_semantics</code> you're telling <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> not to set <code>UnrelatedTargetB</code> as the current target <em>because <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> should assume it already is</em> the current target.</p>
<p>Likewise there should be no barriers to execute because barriers force the pass to 'close' which means store semantics must be executed; and to open another pass we must execute load semantics again (see <code>target_level_barrier</code> to solve this problem).</p>
<p>We try to perform validation checks in Debug mode to avoid these type of errors, but we can't cover them all.</p>
<p>This setting is an optimization specifically aimed at mobile and you should pay attention to errors, the Ogre.log, Vulkan Validation Layers, and tools like RenderDoc to be sure rendering is happening as intended.</p>
<p>The following setting was available in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x; but was not documented:</p>
<ul>
<li>quad_normals [camera_far_corners_view_space|camera_far_corners_view_space_normalized|camera_far_corners_view_space_normalized_lh|camera_far_corners_world_space|camera_far_corners_world_space_centered|camera_direction]</li>
</ul>
<p>Sends through the <code>NORMALS</code> semantic the camera's frustum corners in either world space or view space. This is particularly useful for efficiently reconstructing position using only the depth and the corners. The <code>camera_direction</code> option sends the direction across the frustum and is the same as <code>camera_far_corners_world_space_centered</code> but normalized (values are in range [0;1]) which is useful for sky rendering &amp; atmospheric scattering. See <code>TutorialSky_Postprocess</code> sample.</p>
<p>Interesting read: Reconstructing Position From Depth <a href="http://mynameismjp.wordpress.com/2009/03/10/reconstructing-position-from-depth/">Part I</a>, <a href="http://mynameismjp.wordpress.com/2009/05/05/reconstructing-position-from-depth-continued/">Part II</a>, <a href="http://mynameismjp.wordpress.com/2010/09/05/position-from-depth-3/">Part III</a></p>
<p><code>camera_far_corners_view_space_normalized</code> is like <code>camera_far_corners_view_space</code> but divides the whole vector by the far plane; causing dir.z to be always -1 (but the vector itself isn't unit-length). The one with <code>_lh</code> suffix is the left-handed variant (i.e. dir.z = 1 instead of -1)</p>
<p>Starting <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.0, UV coordinates are always sent to the vertex shader in pass quads.</p>
<blockquote class="doxtable">
<p>&zwj; Attention!</p>
<p>In <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.x; you need to apply the <b>world-view-proj matrix</b> so that the the pass being drawn compensates for texel-to-pixel aligning reads in Direct3D9. Failing to do so will not only cause the aforementioned alignment issue, but also will cause glitches when the viewport is not 0 0 1 1</p>
<p>In <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x, only the proj matrix was necessary to fix texture flipping issues when rendering to FBOs in OpenGL. </p>
</blockquote>
<h3><a class="anchor" id="CompositorNodesPassesResolve"></a>
resolve</h3>
<blockquote class="doxtable">
<p>&zwj; <b>Note:</b> at the time of writing, resolve passes have not been fully implemented </p>
</blockquote>
<p>TBD</p>
<p>When the Render System doesn't support explicit resolves (or textures were created with no msaa setting), textures are treated as implicitly resolved and all resolve passes are ignored.</p>
<p>See *MSAA: Explicit vs Implicit resolves* section for more information.</p>
<h3><a class="anchor" id="CompositorNodesPassesRenderScene"></a>
render_scene</h3>
<p>The syntax is also similar to 1.x; but there were a couple modifications:</p>
<ul>
<li>rq_first &lt;id&gt;;</li>
</ul>
<p>Replaces first_render_queue. The default is 0. Must be a value between 0 and 255. The value is inclusive</p>
<ul>
<li>rq_last &lt;id&gt;;</li>
</ul>
<p>Replaces last_render_queue. The default is <code>max</code> which is a special parameter that implies the last active render queue ID. If numeric, value must be between 0 and 255. The value is <b>not</b> inclusive.</p>
<ul>
<li>skip_load_store_semantics [yes|no];</li>
</ul>
<p>See render_quad.</p>
<ul>
<li>viewport [idx] &lt;left&gt;; &lt;top&gt;; &lt;width&gt;; &lt;height&gt;; [&lt;scissor_left&gt;; &lt;scissor_top&gt;; &lt;scissor_width&gt;; &lt;scissor_height&gt;;]</li>
</ul>
<p>Specifies the viewport. Also supported by all other passes (i.e. clear &amp; quads), The default is <code>0 0 1 1</code> which covers the entire screen. Values should be between 0 and 1.</p>
<p>When 4 parameters are suplied, the scissor box will match the viewport's. All 8 parameters allow to set a custom scissor box. <em>Note:</em> Scissor testing must be enabled by the Hlms Macroblock for it to work, we just set the size here.</p>
<p>When the optional 'idx' parameter is supplied at the begginning there will be either 5 or 9 parameters instead of 4 or 8 respectively. This index allows you to set multiple viewports for e.g. instanced_stereo or for shaders that make use of gl_ViewportIndex/SV_ViewportArrayIndex. When not provided, this value defaults to 0. The value is in range [0; 16)</p>
<p>The Compositor will automatically share Viewport pointers between different passes to the same RenderTarget (even for different nodes) as long as they share the exact same parameters.</p>
<ul>
<li>visibility_mask &lt;number&gt;;</li>
</ul>
<p>Visibility mask to be used by the pass' viewport. Those entities that fail the test '<em>entityMask &amp; visibility_mask</em>' will not be rendered. There are no significant changes to <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x, except that the script compiler now accepts hexadecimal values with the 0x prefix; not just decimal values.</p>
<ul>
<li>light_visibility_mask &lt;number&gt;;</li>
</ul>
<p>Visibility mask to be used by the pass for culling lights in Forward+. Those entities that fail the test '<em>entityMask &amp; light_visibility_mask</em>' will not be used as non-shadow-casting lights during this pass. This will give you a relatively efficient way to control with coarse granularity which lights affect which objects. Note that this uses the mask set via light-&gt;setVisibilityMask, not the one set via light-&gt;setLightMask.</p>
<ul>
<li>shadows &lt;off|shadow_node_name&gt;; &lt;reuse|recalculate|first&gt;;</li>
</ul>
<p>Off by default. Specifies the shadow node to use for rendering with shadow maps. See section about *Shadow Nodes* for more information. When a shadow node's name is provided, the second parameter defaults to <em>first</em>.</p>
<ul>
<li>overlays &lt;off|on&gt;;</li>
</ul>
<p>Whether to Overlays from the OverlaySystem component. On by default for regular nodes, Off by default on shadow nodes. The goal is that eventually Overlays obey RenderQueue IDs like everything else, but it was too hard to port (Overlay system is tad bit complex...) so this hack/flag was created. It will be eventually removed.</p>
<ul>
<li>camera &lt;camera_name&gt;;</li>
</ul>
<p>When not specified, the default camera is used for rendering the pass (this default camera is specified when instantiating the workspace from C++).</p>
<p>When a name is given, the Compositor will look for this camera and use it. Very useful for reflection passes (mirrors, water) where the user wants to be in control of the camera, while the Compositor is associated with it. The Camera must be created by the user before the workspace is instantiated and remain valid until the workspace is destroyed.</p>
<ul>
<li>cull_camera &lt;camera_name&gt;;</li>
</ul>
<p>In VR we want to reuse the same cull list for both eyes. Additionally we'd like to calculate shadows for both eyes once, rather than once per eye. This setting allows setting a cull camera different from the rendering camera that should be placed in such a way that the cull camera's frustum encompases both left and right eye. When this string is empty, the regular camera is used. Default: Empty string.</p>
<ul>
<li>lod_camera &lt;camera_name&gt;;</li>
</ul>
<p>The camera point of view from which the LOD calculations will be based from (i.e. useful for shadow mapping, which needs the LOD to match that of the user camera). When an empty string is provided, <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> will assume the lod camera is the same as the current camera, except for shadow nodes in which it will assume it's the lod_camera from the normal pass the shadow node is attached to. Default: Empty string.</p>
<ul>
<li>lod_update_list [yes|no]</li>
</ul>
<p>When No (or false), the LOD list won't be updated, and will use the LOD lists of calculated by a previous pass. This saves valuable CPU time. Useful for multiple passes using the same lod_camera (without a pass in the middle with a different lod_camera that would override the cached LOD lists). If your application is extremely CPU bound, and hence you don't need LOD, turning this setting to false in all passes will effectively turn lodding off (and alleviate the CPU). Default: Yes; except for passes belonging to shadow nodes, which is forced to false unless lod_camera is a non-empty string.</p>
<ul>
<li>lod_bias &lt;bias&gt;;</li>
</ul>
<p>Applies a bias multiplier to the lod. Valid values are in range [0; Inf). A higher lod bias causes LOD to pop up sooner. Default: 1.0</p>
<ul>
<li>camera_cubemap_reorient [yes|no]</li>
</ul>
<p>When Yes, the camera will be reoriented for rendering cubemaps, depending on which slice of the render target we're rendering to (3D, Cubemaps and 2D-array textures only). Its original orientation is restored after the pass finishes. The rotations are relative to its original orientation, which can produce counter-intuitive results if the Camera wasn't set to identity (unless that's the desired effect). See Passes section on how to indicate which slice should we render to. Default: No.</p>
<p><b>Note:</b> if the target is not a cubemap, <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> will still try to rotate the camera, often to unintended angles.</p>
<ul>
<li>enable_forwardplus [yes|no]</li>
</ul>
<p>When yes, this pass will use Forward3D/ForwardClustered (must be enabled first by the developer via C++, see Forward3D sample). When No, Forward3D will not be used for this pass, which can improve performance both CPU and GPU side (but many lights are likely not going to be drawn or used). Default: Yes.</p>
<p><b>Details:</b> CPU side, lights won't be culled against the camera (only a saving if F3D didn't already have a cache from a previous pass during the same frame, with the exact same camera and angle). GPU side, the pixel shaders will be lighter.</p>
<ul>
<li>flush_command_buffers_after_shadow_node [yes|no]</li>
</ul>
<p>Same as flush_command_buffers. Does not do anything if 'shadows' is set to 'reuse' (or was set to 'first' and this node is not the first)</p>
<ul>
<li>expose &lt;textureName&gt;;</li>
</ul>
<p>Low level materials can access local and global textures via the old 'content_type compositor' setting, and Hlms materials can access them by calling SceneManager::getCompositorTextures. But before you can do that, you need to expose them to the pass. This is necessary so <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> can know which textures may or will be used during the pass so resource transitions and barriers can be issued in explicit APIs like DX12 and Vulkan.</p>
<ul>
<li>is_prepass [yes|no];</li>
</ul>
<p>Indicates this is a prepass render. HlmsPbs implementation will render a GBuffer with normals and shadow mapping information. See ScreenSpaceReflections sample for an example on how to use it.</p>
<ul>
<li>use_prepass &lt;GBuffer&gt; [reflectionBuffer]</li>
</ul>
<p>Indicates this pass will take advantage of the data generated during the prepass, which means depth buffer writes may be forced to off; normals will be sourced for the GBuffer. And if present, a reflection texture will be used for calculating SSR (Screen Space Reflections).</p>
<ul>
<li>instanced_stereo [yes|no]</li>
</ul>
<p>Whether to use instanced stereo, for VR rendering. See InstancedStereo and OpenVR samples. You will probably want to also set multiple viewports, at the very least viewports 0 and 1</p>
<h3><a class="anchor" id="CompositorNodesPassesShadows"></a>
shadows</h3>
<p>This pass enables force-updating multiple shadow nodes in batch in its own pass</p>
<p>This is useful because shadow nodes may "break" a render pass in 3:</p>
<ul>
<li>Normal rendering to RT</li>
<li>Shadow node update</li>
<li>Continue Normal rendering to the same RT</li>
</ul>
<p>This is an unnecessary performance hit on mobile (TBDR) thus executing them earlier allows for a smooth:</p>
<ul>
<li>Shadow node update (all of them? Up to you)</li>
<li>Normal rendering to RT</li>
</ul>
<p>Don't forget to set shadow nodes to reuse in the pass scene passes or else you may overwrite them unnecessarily</p>
<p>Usage is simple:</p>
<div class="fragment"><div class="line"><span class="comment">// This pass supports being part of a nameless target</span></div>
<div class="line">target</div>
<div class="line">{</div>
<div class="line">    pass shadows</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">// We can update multiple shadow nodes</span></div>
<div class="line">        shadows MyShadowNode_0</div>
<div class="line">        shadows MyShadowNode_1</div>
<div class="line">        shadows MyShadowNode_2</div>
<div class="line"> </div>
<div class="line">        <span class="comment">// These 4 parameters are the same as in pass_scene</span></div>
<div class="line">        camera      CameraName</div>
<div class="line">        lod_camera  CameraName</div>
<div class="line">        cull_camera CameraName</div>
<div class="line">        visibility_mask 0xffffffff</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><h3><a class="anchor" id="CompositorNodesPassesStencil"></a>
stencil</h3>
<p>Stencil passes are little more flexible than in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x; always remember to restore the stencil passes before leaving the node otherwise next nodes that will be executed may use unexpected stencil settings.</p>
<p>Most relevant changes are that two sided stencil can now be definted with more flexibility (it's not a boolean anymore), and that syntax has slightly changed to accomodate for this change:</p>
<div class="fragment"><div class="line">pass stencil</div>
<div class="line">{</div>
<div class="line">    check       <span class="keyword">true</span></div>
<div class="line">    mask        0xff</div>
<div class="line">    read_mask   0xff</div>
<div class="line">    </div>
<div class="line">    both</div>
<div class="line">    {</div>
<div class="line">        fail_op     keep</div>
<div class="line">        depth_fail_op   increment</div>
<div class="line">        pass_op     decrement_wrap</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>The <code>read mask</code> is new, and now the <code>fail_op</code>, <code>depth_fail_op</code> &amp; <code>pass_op</code> must be enclosed between brackets.</p>
<p>Valid values are 'both' 'front' and 'back'. 'both' is just a shortcut for defining front and back at the same time with less typing.</p>
<h3><a class="anchor" id="CompositorNodesPassesUavQueue"></a>
uav_queue</h3>
<p>This is a new feature introduced in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.1. s stands for <b>U</b>nordered <b>A</b>ccess <b>V</b>iews, in D3D's jargon. OpenGL users know UAVs as the feature combination of <em>image</em> textures (imageLoad, imageStore) and SSBOs (Shader Storage Buffer Object). UAVs are powerful beasts because they allow random read and write access from a shader, and even support atomic operations. Proper use of them can achieve incredible results that couldn't be done without UAVs, but improper use can severely hurt performance.</p>
<p>There's quite a discrepancy between D3D11 &amp; OpenGL in how they treat UAVs from API interface perspective. D3D11 equals UAVs to RenderTargets; while OpenGL equals them more like textures.</p>
<p>In fact, the D3D11 API call to bind UAVs must set RenderTargets at the same time. There is no API call to only set UAVs. To make things harder, D3D11 forces UAVs to share slots with RenderTargets; and there are up to 8 slots in total (64 when using D3D11.1 on Windows 8.1). Which means if you're using an MRT with 3 targets, you only have 5 slots left for UAVs.</p>
<p>We can guess for performance improvements: this way D3D11 can check for hazards when setting RTs and UAVs (i.e. make sure you don't bind the same resource as both RT and UAV) while they still use the same hazard checking they do for textures to check that you're not binding a texture at the same time it is bound as an RT/UAV.</p>
<p>If the UAV equals a texture, as in OpenGL; they would have to check textures against textures every time a texture changes, which is O( N! ) complexity; and also a very common operation. Considering past experiences, we're guessing OpenGL just simply skips the check and lets the hazard happen (which is cool when there are hardware extensions that allow you to read/write from these resources at the same time as long as you abide to certain rules).</p>
<p>Because D3D11 is more restrictive than OpenGL, our interface resemble's D3D11.</p>
<ul>
<li>starting_slot &lt;number&gt;;</li>
</ul>
<p>Offset for all UAV slots. For example if you bind an uav to slot 3 and the starting slot is 2; the uav will actually be bound to uav slot 5. When set to 255, the slot offset is ignore and leaves the last setting made.</p>
<p>Default: 255 (by default <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> sets it to 1).</p>
<ul>
<li>uav &lt;slot&gt;; &lt;texture_name&gt;; [mrt #] &lt;read&gt;; &lt;write&gt;; [pixel_format] [&lt;mipmap&gt;; #]</li>
</ul>
<p>Sets a texture visible in the current compositor scope (i.e. global textures, input textures, local textures). Slot, name and at least read or write flags must be present. The others are optional and default to 0 (mrt &amp; mipmap) and <code>PF_UNKNOWN</code> (format, <code>PF_UNKNOWN</code> means the UAV will use the original texture's pixel format instead of trying to reinterpret the data).</p>
<p>The keyword mipmap must be present if specifying the mipmap level.</p>
<p>Example, assuming <code>starting_slot</code> is 1:</p>
<div class="fragment"><div class="line">uav 0 global_myTexture 2 read write mipmap 5</div>
</div><!-- fragment --><p>Will bind the mrt slice #2 of the global texture 'global_myTexture' to slot 1[^5], will have both read &amp; write access, and use mipmap level 5.</p>
<p>If only the slot is specified, any UAV at the given slot will be cleared.</p>
<ul>
<li>uav_external</li>
</ul>
<p>Exactly the same as uav. But instead of sourcing the texture by name from the Compositor scope, the name is referencing a texture that can be accessed via <code>TextureManager::getByName</code>.</p>
<ul>
<li>uav_buffer &lt;slot&gt;; &lt;bufferName&gt;; &lt;read&gt;; &lt;write&gt;; [offsetBytes] [sizeBytes]</li>
</ul>
<p>Sets an UAV buffer visible in the current compositor scope (i.e. global buffers, input buffers, local buffers). Slot, name and at least read or write flags must be present. The others are optional and default to 0. When sizeBytes = 0; we assume you want to bind from the offset until the end of the buffer.</p>
<p>Example, assuming starting_slot is 1:</p>
<div class="fragment"><div class="line">uav_buffer 0 myUavBuffer read write 256 512</div>
</div><!-- fragment --><p>Note there may be HW alignment restriction on which offset you specify. Multiples of 256 bytes are a safe bet.</p>
<p>Note that uav_buffer slots are shared with uav texture's. Binding both to the same slot index will only result in one of them being available.</p>
<p>If only the slot is specified, any UAV at the given slot will be cleared.</p>
<ul>
<li>keep_previous_uavs [true|false]</li>
</ul>
<p>When false, all previous UAVs in all slot will be cleared. When true, only the UAV slots modified by this pass will be affected. Default: true.</p>
<h4><a class="anchor" id="CompositorNodesPassesUavQueueSync"></a>
Synchronization</h4>
<p>UAVs make little guarantees about the order of read and writes. Often memory barriers need to be placed to result in correct rendering.</p>
<p>OpenGL uses a coarse barrier (affects all resources that will be used as a specific type); while D3D12 uses a fine barrier (per resource). Therefore we need to take D3D12's approach.</p>
<p>The Compositor can detect when an UAV will be used in a <code>PASS_QUAD</code> pass as a texture, and thus it will automatically insert memory barriers. However it cannot detect if the pass will use an UAV that was just been used for writing as an UAV for reading, and hence the user must insert a barrier manually. (TODO: No interface to do this yet!)</p>
<p>The compositor textures that are explicitly made visible to passes to be used as textures (i.e. in a <code>CompositorPassScene</code>) can also be detected and a memory barrier will automatically be placed.</p>
<p>TODO: !!!Interface WIP. Code may not work as described in this section!!!</p>
<blockquote class="doxtable">
<p>&zwj; <b>Note:</b> at the time of writing, memory barriers are a Work In Progress. Documentation may change! </p>
</blockquote>
<h3><a class="anchor" id="CompositorNodesPassesCompute"></a>
compute</h3>
<p>Compute passes let you run a compute job. It can read textures, read/write to UAV textures, and read/write to UAV buffers.</p>
<ul>
<li>job &lt;job_name&gt;;</li>
</ul>
<p>Sets the name of the compute job to run (an HlmsComputeJob).</p>
<ul>
<li>uav &lt;slot&gt;; &lt;texture_name&gt;; [mrt #] &lt;read&gt;; &lt;write&gt;; [pixel_format] [&lt;mipmap&gt;; #] [allow_write_after_write]</li>
</ul>
<p>See <code>uav_queue</code>'s description. The presense of <code>allow_write_after_write</code> means the compositor will not insert a barrier between to consecutive passes that writes to the UAV without reading.</p>
<ul>
<li>uav_buffer &lt;slot&gt;; &lt;bufferName&gt;; &lt;read&gt;; &lt;write&gt;; [offsetBytes] [sizeBytes] [allow_write_after_write]</li>
</ul>
<p>See <code>uav_queue</code>'s description. The presense of <code>allow_write_after_write</code> means the compositor will not insert a barrier between to consecutive passes that writes to the UAV without reading.</p>
<ul>
<li>input &lt;slot&gt;; &lt;texture_name&gt;; [mrt #]</li>
</ul>
<p>Binds a texture to the texture unit. Syntax is the same as <code>pass_quad</code>. The slot is not shared with the uav's.</p>
<p>Compute passes don't really belong to a render target. However due to the Compositor's design, they must be specified within a render target. You may do so within a valid render target:</p>
<div class="fragment"><div class="line">compositor_node MyNode</div>
<div class="line">{</div>
<div class="line">    in 0 rt_renderwindow</div>
<div class="line">    texture myUavTexture target_width target_height PF_R8G8B8A8 depth_pool 0 no_gamma uav</div>
<div class="line">    buffer myUavBuffer 1024 4</div>
<div class="line">    </div>
<div class="line">    target rt_renderwindow</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">//Run compute job with myUavTexture &amp; myUavBuffer bound.</span></div>
<div class="line">        pass compute</div>
<div class="line">        {</div>
<div class="line">            job myComputeJobName</div>
<div class="line">            uav 0 myUavTexture read write</div>
<div class="line">            uav_buffer 1 myUavBuffer read write</div>
<div class="line">        }</div>
<div class="line">        <span class="comment">//Clear  rt_renderwindow to violet</span></div>
<div class="line">        pass clear</div>
<div class="line">        {</div>
<div class="line">            colour_value 1 0 1 1</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    out 0 myUavTexture</div>
<div class="line">    out_buffer 0 myUavBuffer</div>
<div class="line">}</div>
</div><!-- fragment --><p>Or to a null dummy render target, which occupies almost no memory:</p>
<div class="fragment"><div class="line">compositor_node MyNode</div>
<div class="line">{</div>
<div class="line">    texture nullDummy target_width target_height PF_NULL</div>
<div class="line">    texture myUavTexture target_width target_height PF_R8G8B8A8 depth_pool 0 no_gamma uav</div>
<div class="line">    buffer myUavBuffer 1024 4</div>
<div class="line">    </div>
<div class="line">    target  nullDummy</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">//Run compute job with myUavTexture bound.</span></div>
<div class="line">        pass compute</div>
<div class="line">        {</div>
<div class="line">            job myComputeJobName</div>
<div class="line">            uav 0 myUavTexture read write</div>
<div class="line">            uav_buffer 1 myUavBuffer read write</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    out 0 myUavTexture</div>
<div class="line">    out_buffer 0 myUavBuffer</div>
<div class="line">}</div>
</div><!-- fragment --><blockquote class="doxtable">
<p>&zwj; Attention #1!</p>
<p>Do NOT set UAV buffers to the compute job directly (the class HlmsComputeJob). The Compositor needs to evaluate memory barriers and resource transitions. Leaving inconsistent memory barriers can result in hazards/race conditions in some APIs. If in doubt, change the CompositorPassComputeDef instead.</p>
<p>Also setting Textures that are RenderTargets is dangerous. For RenderTargets, change the CompositorPassComputeDef instead.</p>
<p>Attention #2!</p>
<p>Don't interleave compute and graphics passes. For optimum performance, try to batch everything together. </p>
</blockquote>
<h2><a class="anchor" id="CompositorNodesTextures"></a>
Textures</h2>
<div class="fragment"><div class="line">texture &lt;name&gt; &lt;width&gt; &lt;height&gt; [depth] &lt;pixel_format&gt; [&lt;mrt_pixel_format2&gt;] [&lt;pixel_formatN&gt;] [no_gamma]</div>
<div class="line">[no_fsaa] [depth_texture] [depth_pool &lt;poolId&gt;] [uav] [2d_array|3d|cubemap] [mipmaps &lt;numMips&gt;] [automipmaps]</div>
<div class="line">[explicit_resolve]</div>
</div><!-- fragment --><ul>
<li>&lt;name&gt;</li>
</ul>
<p>A locally unique name must be assigned (and cannot start with <em>global_</em> prefix).</p>
<ul>
<li>&lt;width&gt; &lt;height&gt;</li>
</ul>
<p>The dimensions of the render texture. You can either specify a fixed width and height, or you can request that the texture is based on the physical dimensions of the viewport to which the compositor is attached. The options for the latter are ’target_width’, ’target_height’, ’target_width_scaled &lt;factor&gt;’ and ’target_height_scaled &lt;factor&gt;’ - where ’factor’ is the amount by which you wish to multiply the size of the main target to derive the dimensions.</p>
<ul>
<li>&lt;depth&gt;</li>
</ul>
<p>Used by 2d_array and 3d textures. Specifies their depth / number of slices. It's automatically forced to 1 for 2d textures and 6 for cubemaps.</p>
<ul>
<li>&lt;pixel_format&gt;</li>
</ul>
<p>The pixel format of the render texture. This affects how much memory it will take, what colour channels will be available, and what precision you will have within those channels. Most common options are PF_A8R8G8B8, PF_R8G8B8A8, PF_FLOAT16_RGBA, PF_FLOAT16_RGB, PF_FLOAT16_R, PF_FLOAT32_RGBA, PF_FLOAT32_RGB, PF_FLOAT32_R.</p>
<ul>
<li>no_fsaa</li>
</ul>
<p>When this keyword is present, the texture will not be using FSAA. The FSAA setting is determined by the main render target.</p>
<ul>
<li>no_gamma</li>
</ul>
<p>By default <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> will perform automatic HW gamma conversion for you (when supported by the hardware) based on system settings. But when this is present, you can override that behavior.</p>
<ul>
<li>depth_pool</li>
</ul>
<p>When present, this directive has to be followed by an integer. This one sets from which Depth buffer pool the depth buffer will be chosen from. All RTs from all compositors with the same pool ID share the same depth buffers as long as it's possible (must have the same resolution, must have the same depth_texture setting). RenderWindows can**not** share their depth buffers due to API limitations on some RenderSystems. When the pool ID is 0, no depth buffer is used. This can be helpful for passes that don’t require a Depth buffer at all, potentially saving performance and memory. Default value is 1.</p>
<ul>
<li>depth_texture</li>
</ul>
<p>When present, the RTT indicates you want to later access the depth buffer's contents as a texture in a shader. RTTs using depth_texture with the same depth pool ID will share depth buffers, but they won't share depth buffers with other RTTs of the same depth pool IDs who don't have depth_texture setting. This setting is implicit when using a depth pixel format such as PF_D24_UNORM_X8</p>
<ul>
<li>uav</li>
</ul>
<p>When present, the texture can be used as an UAV.</p>
<ul>
<li>2d_array|3d|cubemap</li>
</ul>
<p>When present, the texture will be created as a 2d_array, 3d or cubemap. Mostly relevant for UAVs but is also useful for rendering. See Target slice parameter.</p>
<ul>
<li>mipmaps &lt;num Mipmaps&gt;</li>
</ul>
<p>Default: 1; Indicates how many mipmaps to use. 1 for none. Use 0 to fill all mipmaps until 1x1</p>
<ul>
<li>automipmaps</li>
</ul>
<p>When present, automipmapping is used. Every time you alter an RTT (e.g. by rendering to it, by clearing it, etc), it is tagged as dirty. When it's used as a texture again, mipmaps will be autogenerated. This can be problematic in certain cases where ping ponging RTTs is involved and you only want to get mipmaps generated at the end. In such cases, consider using using a PASS_ instead to manually generate them.</p>
<ul>
<li>explicit_resolve</li>
</ul>
<p>When present, <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> shall not resolve the MSAA contents every time you want to access it as a texture; but rather when you do that explicitly, thus until it's not manually resolved; you can access the internal MSAA contents.</p>
<h3><a class="anchor" id="CompositorNodesTexturesMsaa"></a>
MSAA: Explicit vs Implicit resolves</h3>
<p>Not long ago, MSAA support was automatic, and worked flawlessly with forward renderers and no postprocessing. Direct3D 9 and OpenGL were not able to access the individual MSAA subsamples from shaders at all.</p>
<p>Fast forward to the present, MSAA resolving should be performed after HDR to avoid halos around edges, and deferred shading can't resolve the G-Buffer otherwise aliasing only gets worse.</p>
<p>Direct3D10 and GL 3.2 introduced the ability of access the MSAA subsamples from a shader, also giving the ability to write custom resolves.</p>
<p>For those unaware what "resolving MSAA" means; a very brief explanation is that when rendering using 2xMSAA, we're actually rendering to a RT that is twice the resolution. "Resolving" is the act of scaling down the resolution into the real RT (i.e. think of Photoshop or Gimp's downscale filter modes). See the Resources section at the end for links to detailed explanations of how MSAA works.</p>
<p>To cleanly deal with this new feature without breaking compatibility with D3D9 &amp; older GL render systems while at the same time being able to effortlessly switch MSAA on and off; the notion of "Explicit" and "Implicit" resolves were added.</p>
<h4><a class="anchor" id="CompositorNodesTexturesMsaaImplicit"></a>
Implicit resolves</h4>
<p>By default all RTTs are implicitly resolved. The behavior of implicitly resolved textures mimics <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x (except for implementation and design issues in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.x that could cause an RTT to resolve multiple times per frame unnecessarily)</p>
<p>The RTT has an internal flag for being "dirty". The texture gets dirty when rendering to it; and it stops being dirty when it is resolved.</p>
<p>When you attempt to bind a dirty RTTs as a texture, you're forcing <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> to resolve it. This means that you should try to delay using the RTT as a texture as much as possible until you've done with rendering to it.</p>
<p>Otherwise the RTT may resolve more than once if you render to it: render (gets dirty), use it as a texture, render to it again (gets dirty again), and use again as a texture (all in the same frame). In some cases this is unavoidable, but often it isn't.</p>
<h4><a class="anchor" id="CompositorNodesTexturesMsaaExplicit"></a>
Explicit resolves</h4>
<p>Explicit resolves are used when you want to either implement a custom resolve other than the API's default; or you want access to the MSAA subsamples directly through shaders.</p>
<p>Like implicit resolves, RTTs have a dirty flag. However:</p>
<ol type="1">
<li>Attempting to bind a dirty RTT as a texture will cause <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> to send the MSAA buffer; granting the shader the ability to access subsamples.</li>
<li>Attempting to bind a non-dirty dirty RTT as a texture will cause <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> to send the resolved buffer. The shader won't be able to access subsamples.</li>
</ol>
<p>In summary, shaders can access subsamples while a texture is dirty. To clean the dirty flag and perform a resolve on the RTT, use the PASS\_RESOLVE pass. This is why they're called "explicit" resolves; because you have to *explicitly *tell <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> to resolve an msaa target and unset the dirty flag[^6].</p>
<p>On RenderSystems where explicit resolving is not supported, all textures will be treated as implicitly resolved and PASS_RESOLVE passes will be ignored; which should work straightforward and without issues except for a few corner cases.</p>
<p>Use the RSC_EXPLICIT_FSAA_RESOLVE Render system capability flag to check if the API supports explicit resolves.</p>
<h4><a class="anchor" id="CompositorNodesTexturesMsaaResources"></a>
Resources</h4>
<ul>
<li><a href="http://mynameismjp.wordpress.com/2012/10/24/msaa-overview/">A Quick Overview of MSAA</a></li>
<li><a href="http://mynameismjp.wordpress.com/2012/10/28/msaa-resolve-filters/">Experimenting with Reconstruction Filters for MSAA Resolve</a></li>
</ul>
<h3><a class="anchor" id="CompositorNodesTexturesDepth"></a>
Depth Textures</h3>
<p>Since <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.1; depth textures are supported. It has been a feature missing from <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> since a long time by now.</p>
<p>Depth textures are a bit particular because they may not "own" the depth buffer. They're just a null render target with a "view" on an already existing depth buffer. But... what does this mean?</p>
<p>Depth Buffers can be tricky. Suppose the following example:</p>
<div class="fragment"><div class="line">compositor_node Example</div>
<div class="line">{</div>
<div class="line">        texture myDepthTexture 512 512 PF_D32_FLOAT</div>
<div class="line">        texture finalSSAO 512 512 PF_R8G8B8</div>
<div class="line">        <span class="comment">//Draw the depth</span></div>
<div class="line">        target myDepthTexture</div>
<div class="line">        {</div>
<div class="line">                pass clear {}</div>
<div class="line">                pass render_scene</div>
<div class="line">                {</div>
<div class="line">                }</div>
<div class="line">        }</div>
<div class="line">        </div>
<div class="line">        target finalSSAO</div>
<div class="line">        {</div>
<div class="line">                pass clear {}</div>
<div class="line">                pass render_quad</div>
<div class="line">                {</div>
<div class="line">                        material DepthAnalysis</div>
<div class="line">                        input 0 myDepthTexture</div>
<div class="line">                }</div>
<div class="line">        }</div>
<div class="line">        </div>
<div class="line">        out 0 finalSSAO</div>
<div class="line">}</div>
</div><!-- fragment --><p>Which simply does "Render a depth only pass to myDepthTexture; and read
the depth buffer contents with a render quad, and store the results in a
coloured RTT called 'finalSSAO' ".</p>
<p>That one was easy. But what about this one?</p>
<div class="fragment"><div class="line">compositor_node Example2</div>
<div class="line">{</div>
<div class="line">        texture firstPass 512 512 PF_R8G8B8</div>
<div class="line">        texture finalColour 512 512 PF_R8G8B8</div>
<div class="line">        <span class="comment">//Draw everything, colour and depth</span></div>
<div class="line">        target firstPass</div>
<div class="line">        {</div>
<div class="line">                pass clear {}</div>
<div class="line">                pass render_scene</div>
<div class="line">                {</div>
<div class="line">                }</div>
<div class="line">        }</div>
<div class="line">        </div>
<div class="line">        target finalColour</div>
<div class="line">        {</div>
<div class="line">                pass clear {}</div>
<div class="line">                pass render_quad</div>
<div class="line">                {</div>
<div class="line">                        material SSAO</div>
<div class="line">                        input 0 ??? <span class="comment">// Depth, firstPass&#39; depth texture?</span></div>
<div class="line">                        input 1 firstPass</div>
<div class="line">                }</div>
<div class="line">        }</div>
<div class="line">        </div>
<div class="line">        out 0 finalColour</div>
<div class="line">}</div>
</div><!-- fragment --><p>The first pass is a pass that includes both colour and depth. The second one, we want to just take the depth and colour buffers separately as input textures to the SSAO material pass.</p>
<p>But how do we take the depth buffer? For that, we need to do two steps:</p>
<ol type="1">
<li>Request the original RTT that it wants to use a depth texture.</li>
<li>Create a depth texture that will be a "view" to the depth buffer. Depth buffer sharing system should assign the same depth buffer to the RTT and the depth texture "view".</li>
</ol>
<p>The solution is the following:</p>
<div class="fragment"><div class="line">compositor_node Example2_fixed</div>
<div class="line">{</div>
<div class="line">        <span class="comment">//Instruct we want to use a depth texture (32-bit float). The &quot;depth_texture&quot; keyword is necessary.</span></div>
<div class="line">        <span class="comment">//Specifying The depth format is optional and so is the depth pool. However recommended to specify</span></div>
<div class="line">        <span class="comment">//them to avoid surprises.</span></div>
<div class="line">        texture firstPass 512 512 PF_R8G8B8 depth_format PF_D32_FLOAT depth_texture depth_pool 1</div>
<div class="line">        <span class="comment">//Declare the depth texture view (which becomes so by using PF_D32_FLOAT as format).</span></div>
<div class="line">        <span class="comment">//Settings MUST match (depth format, pools, resolution). Specifying the depth pool is necessary,</span></div>
<div class="line">        <span class="comment">//otherwise the depth texture will get its own depth buffer, instead of becoming a view.</span></div>
<div class="line">        texture firstPassDepthTexture 512 512 PF_D32_FLOAT depth_pool 1</div>
<div class="line">        texture finalColour 512 512 PF_R8G8B8</div>
<div class="line">        <span class="comment">//Draw everything, colour and depth</span></div>
<div class="line">        target firstPass</div>
<div class="line">        {</div>
<div class="line">                pass clear {}</div>
<div class="line">                pass render_scene</div>
<div class="line">                {</div>
<div class="line">                }</div>
<div class="line">        }</div>
<div class="line">        </div>
<div class="line">        target finalColour</div>
<div class="line">        {</div>
<div class="line">                pass clear {}</div>
<div class="line">                pass render_quad</div>
<div class="line">                {</div>
<div class="line">                        material SSAO</div>
<div class="line">                        input 0 firstPassDepthTexture</div>
<div class="line">                        input 1 firstPass</div>
<div class="line">                }</div>
<div class="line">        }</div>
<div class="line">        </div>
<div class="line">        out 0 finalColour</div>
<div class="line">}</div>
</div><!-- fragment --><blockquote class="doxtable">
<p>&zwj; Attention #1!</p>
<p>On a lot of Hardware, depth buffers are compressed (see <a href="http://amd-dev.wpengine.netdna-cdn.com/wordpress/media/2012/10/Depth_in-depth.pdf">Depth In Depth</a> and <a href="http://amd-dev.wpengine.netdna-cdn.com/wordpress/media/2012/10/ATI_Radeon_HD_2000_programming_guide.pdf">ATI Radeon HD 2000 Programming Guide</a>). Before AMD's GCN Taihiti hardware (AMD Radeon R9 280), <b>depth buffers need to be decompressed when bound for sampling as a depth texture.</b> Trying to use the depth texture as a depth buffer again without clearing it will degrade due to the lack of compression.</p>
<p>It is suggested to copy the depth texture to another depth texture if you desire to use one for sampling and another to keep rendering, in order to maximize performance.</p>
<p>The specifics of depth (de)compression for NVIDIA and Intel aren't known but it's probable they're bound to similar issues.</p>
<p>TODO: Compositor interface to copy depth texture to another depth texture automatically. </p>
</blockquote>
<h1><a class="anchor" id="CompositorShadowNodes"></a>
Shadow Nodes</h1>
<p>The only way to have shadows in <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> is through shadow nodes.</p>
<p>Stencil shadows and "textured shadows" have been removed from <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.0; only depth shadow maps are supported.</p>
<p>A shadow node is a special type of Node (in fact, the class inherits from CompositorNode) that is executed inside a regular node (normally, a render_scene pass) instead of being connected to other nodes.</p>
<p>It is possible however, to connect the output from a Shadow Node to a regular Node for further postprocessing (i.e. reflective shadow maps for real time Global Illumination), but Shadow Nodes cannot have input. <em>This particular feature (output to regular nodes) is still a work in progress at the time of writing since ensuring the regular node is executed after the shadow node has been executed can be a bit tricky</em>.</p>
<h2><a class="anchor" id="CompositorShadowNodesSetup"></a>
Setting up shadow nodes</h2>
<p>Shadow nodes work very similar to regular nodes. Perhaps their most noticeable difference is how are RTTs defined. The following keywords are supposed at shadow node scope:</p>
<ul>
<li>technique &lt;uniform|planeoptimal|focused|pssm&gt;;</li>
</ul>
<p>Specifies which shadow technique to use for the subsequent shadow map declarations. The default is uniform.</p>
<blockquote class="doxtable">
<p>&zwj; <b>Note:</b> planeoptimal has also not been implemented yet. </p>
</blockquote>
<ul>
<li>num_splits &lt;num_splits&gt;</li>
</ul>
<p>Only used by PSSM techniques. Specifies the number of splits per light. Can vary per shadow map. The number of splits must be greater than 2. Default is 3.</p>
<ul>
<li>num_stable_splits &lt;num_stable_splits&gt;</li>
</ul>
<p>PSSM tends to be very unstable to camera rotation changes. Rotate the camera around and the shadow mapping artifacts keep changing.</p>
<p>setNumStableSplits allows you to fix that problem; by switching to ConcentricShadowCamera for the first N splits you specify; while the rest of the splits will use FocusedShadowCameraSetup.</p>
<p>We achieve rotation stability by sacrificing overall quality. Using ConcentricShadowCamera on higher splits means sacrificing exponentially a lot more quality (and even performance); thus the recommended values are num_stable_splits = 1 or num_stable_splits = 2</p>
<p>The default is num_stable_splits = 0 which disables the feature</p>
<ul>
<li>normal_offset_bias </li>
</ul>
<p>Normal-offset bias is per cascade / shadow map to fight shadow acne and self shadowing artifacts Very large values can cause misalignments between the objects and their shadows (if they're touching)</p>
<p>Default is 0.00004</p>
<ul>
<li>constant_bias_scale </li>
</ul>
<p>Constant bias is per material (tweak HlmsDatablock::mShadowConstantBias). This value lets you multiply it 'mShadowConstantBias * constantBiasScale' per cascade / shadow map</p>
<p>Large values can cause peter-panning.</p>
<p>Default is 0.1 for backwards compatibility with older materials created by <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.2.2 and earlier</p>
<ul>
<li>pssm_lambda &lt;lambda&gt;</li>
</ul>
<p>Only used by PSSM techniques. Value usually between 0 &amp; 1. The default is 0.95. PSSM's lambda is a weight value for a linear interpolation between exponential and linear separation between each split. A higher lambda will use exponential distribution, thus closer shadows will improve quality. A lower lambda will use a linear distribution, pushing the splits further, improving the quality of shadows in the distance.</p>
<ul>
<li>pssm_split_blend &lt;blend&gt;</li>
</ul>
<p>Only used by PSSM techniques. Value between 0 &amp; 1. The default is 0.125; use 0 to disable it. PSSM's blend defines, in the closest N-1 splits, the blend band size. E.g., a value of 0.1 means that the farthest 10% of the first split is blended with the second split (and so on for the other splits). A higher blend reduces visible seams between splits at a cost of a slightly less defined shadow. See [Blend between Cascades] (<a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ee416307(v=vs.85).aspx">https://msdn.microsoft.com/en-us/library/windows/desktop/ee416307(v=vs.85).aspx</a>) for additional info.</p>
<ul>
<li>pssm_split_fade &lt;fade&gt;</li>
</ul>
<p>Only used by PSSM techniques. Value between 0 &amp; 1. The default is 0.313; use 0 to disable it. PSSM's fade defines how much of the last split will fade out. E.g., a value of 0.1 means that the farthest 10% of the last split will fade out. A higher fade makes the transition from shadowed to non shadowed areas (and viceversa) smoother at a cost of a less visible distant shadow.</p>
<div class="fragment"><div class="line">shadow_map &lt;number&gt; &lt;texture_name&gt; light &lt;lightIndex&gt; [split &lt;index&gt;]</div>
<div class="line">shadow_map &lt;number&gt; [atlas &lt;texture_name&gt; &lt;left&gt; &lt;top&gt; &lt;width&gt; &lt;height&gt;] light &lt;lightIndex&gt; [split &lt;index&gt;]</div>
</div><!-- fragment --><p>Shadow maps declaration order is important. The first shadow map declared becomes shadow map #0; the second shadow map declared becomes #1; and so on. Most of the settings are the same as for regular textures. So only the new settings or the ones that behave differently will be described:</p>
<ul>
<li>texture_name</li>
</ul>
<p>What texture to use that has already been declared, where the shadow map contents will be stored.</p>
<ul>
<li>atlas &lt;texture_name&gt; &lt;left&gt; &lt;top&gt; &lt;width&gt; &lt;height&gt;</li>
</ul>
<p>Instead of using the whole atlas content, you can use a region of it. The values are in range [0;1]</p>
<ul>
<li>light &lt;index&gt;;</li>
</ul>
<p>Indicates which light index will be associated with this shadow map. i.e. the Shadow map #0 may contain the Nth closest shadow mapping light to the entity, not necessarily the first one.</p>
<ul>
<li>split &lt;split index&gt;;</li>
</ul>
<p>Default: 0; only necessary when using PSSM techniques. Indicates which split this shadow map refers to.</p>
<div class="fragment"><div class="line">shadow_map &lt;shadowMapName0&gt; &lt;shadowMapName1&gt; {}</div>
</div><!-- fragment --><p>Declaring a shadow map is not enough. You need to tell <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> what do you want to render to it. And for that you need render_scene passes.</p>
<p>Shadow nodes can be written with the regular <code>target { pass render_scene {} }</code> syntax. However when you have 6 shadow maps with the same exact pass settings, it's cumbersome to write the pass six times. Instead the <code>shadow_map</code> keyword repeats the passes for you.</p>
<h2><a class="anchor" id="CompositorShadowNodesExample"></a>
Example</h2>
<p>The following is a basic script that will set a single shadow map with a focused setup:</p>
<div class="fragment"><div class="line">compositor_node_shadow myShadowNode</div>
<div class="line">{</div>
<div class="line">    technique focused</div>
<div class="line">    texture focusedTex 2048 2048 PF_D32_FLOAT no_fsaa</div>
<div class="line">    shadow_map 0 focusedTex light 0</div>
<div class="line">    <span class="comment">//Render shadow map &quot;0&quot;</span></div>
<div class="line">    shadow_map_target_type directional spot</div>
<div class="line">    {</div>
<div class="line">        shadow_map 0</div>
<div class="line">        {</div>
<div class="line">            pass clear { colour_value 1 1 1 1 }</div>
<div class="line">            pass render_scene</div>
<div class="line">            {</div>
<div class="line">                rq_first 0</div>
<div class="line">                rq_last max</div>
<div class="line">            }</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>The typical setup is to have one directional light for the sun, and then multiple point or spot lights. This means directional light should use a PSSM setting for best quality, while point &amp; spot lights shadow maps could use focused or uniform.</p>
<p>The following script creates 3 shadow maps for 3 PSSM splits, and 3 additional ones for the remaining lights:</p>
<div class="fragment"><div class="line">compositor_node_shadow myShadowNode</div>
<div class="line">{</div>
<div class="line">    <span class="comment">//Change to focused from now on</span></div>
<div class="line">    technique focused</div>
<div class="line">    shadow_map 3 1024 1024 PF_FLOAT16_R light 1</div>
<div class="line">    shadow_map 4 1024 1024 PF_FLOAT16_R light 2</div>
<div class="line">    shadow_map 5 512 512 PF_FLOAT16_R light 3</div>
<div class="line"> </div>
<div class="line">    <span class="comment">//Render shadow maps &quot;myStringName&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot; and &quot;5&quot;</span></div>
<div class="line">    shadow_map myStringName 1 2 3 4 5</div>
<div class="line">    {</div>
<div class="line">        pass clear { colour_value 1 1 1 1 }</div>
<div class="line">        pass render_scene</div>
<div class="line">        {</div>
<div class="line">            rq_first 0</div>
<div class="line">            rq_last max</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">    technique pssm</div>
<div class="line"> </div>
<div class="line">    texture pssm0 2048 2048 PF_D32_FLOAT</div>
<div class="line">    texture pssm1 1024 1024 PF_D32_FLOAT</div>
<div class="line">    texture pssm2 1024 1024 PF_D32_FLOAT</div>
<div class="line"> </div>
<div class="line">    texture spot0 2048 2048 PF_D32_FLOAT</div>
<div class="line">    texture spot1 2048 2048 PF_D32_FLOAT</div>
<div class="line"> </div>
<div class="line">    num_splits      3</div>
<div class="line">    pssm_lambda     0.95</div>
<div class="line">    <span class="comment">//Render 1st closest light, splits 0 1 &amp; 2</span></div>
<div class="line">    shadow_map 0 pssm0 light 0 split 0</div>
<div class="line">    shadow_map 1 pssm1 light 0 split 1</div>
<div class="line">    shadow_map 2 pssm2 light 0 split 2</div>
<div class="line"> </div>
<div class="line">    <span class="comment">//Change to focused from now on</span></div>
<div class="line">    technique focused</div>
<div class="line">    shadow_map 3 spot0 light 1</div>
<div class="line">    shadow_map 4 spot1 light 2</div>
<div class="line"> </div>
<div class="line">    shadow_map_target_type directional</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">//Render shadow maps 0, 1 and 2.</span></div>
<div class="line">        <span class="comment">//Can only be used by directional lights.</span></div>
<div class="line">        shadow_map 0 1 2</div>
<div class="line">        {</div>
<div class="line">            pass clear</div>
<div class="line">            {</div>
<div class="line">                colour_value 1 1 1 1</div>
<div class="line">            }</div>
<div class="line">            pass render_scene</div>
<div class="line">            {</div>
<div class="line">            }</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    shadow_map_target_type directional spot</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">//Render shadow maps 3 and 4</span></div>
<div class="line">        <span class="comment">//Can only be used by either directional lights or spot lights.</span></div>
<div class="line">        shadow_map 3 4</div>
<div class="line">        {</div>
<div class="line">            pass clear</div>
<div class="line">            {</div>
<div class="line">                colour_value 1 1 1 1</div>
<div class="line">            }</div>
<div class="line">            pass render_scene</div>
<div class="line">            {</div>
<div class="line">            }</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="CompositorShadowNodesAtlasAndPointLights"></a>
Shadow map atlas &amp; Point Lights</h2>
<p>Instead of rendering each PSSM split into a different texture, you can use an atlas:</p>
<div class="fragment"><div class="line">compositor_node_shadow PssmWithAtlas</div>
<div class="line">{</div>
<div class="line">    technique pssm</div>
<div class="line"> </div>
<div class="line">    texture atlas 3072 2048 PF_D32_FLOAT no_fsaa</div>
<div class="line"> </div>
<div class="line">    <span class="comment">//The splits are distributed in the atlas like this:</span></div>
<div class="line">    <span class="comment">//  -------------</span></div>
<div class="line">    <span class="comment">//  |     |  2  |</span></div>
<div class="line">    <span class="comment">//  |  1  |-----|</span></div>
<div class="line">    <span class="comment">//  |     |  3  |</span></div>
<div class="line">    <span class="comment">//  -------------</span></div>
<div class="line">    num_splits      3</div>
<div class="line">    pssm_lambda     0.95</div>
<div class="line">    shadow_map 0 atlas uv 0.000000000000000 0.0 0.666666666666667 1.0 light 0 split 0</div>
<div class="line">    shadow_map 1 atlas uv 0.666666666666667 0.0 0.333333333333333 0.5 light 0 split 1</div>
<div class="line">    shadow_map 2 atlas uv 0.666666666666667 0.5 0.333333333333333 0.5 light 0 split 2</div>
<div class="line"> </div>
<div class="line">    <span class="comment">//Before doing anything, clear the whole atlas in one go. This is not</span></div>
<div class="line">    <span class="comment">//recommended on iOS &amp; Android though; but recommended on Desktop.</span></div>
<div class="line">    target atlas</div>
<div class="line">    {</div>
<div class="line">        pass clear</div>
<div class="line">        {</div>
<div class="line">            colour_value 1 1 1 1</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    shadow_map_target_type directional</div>
<div class="line">    {</div>
<div class="line">        shadow_map 0 1 2</div>
<div class="line">        {</div>
<div class="line">            pass render_scene</div>
<div class="line">            {</div>
<div class="line">                <span class="comment">//The viewport settings will be automatically</span></div>
<div class="line">                <span class="comment">//adjusted to constrain to the atlas regions.</span></div>
<div class="line">            }</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>Point light shadow mapping has to exploit the powerful compositor scripting capabilities: <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> uses DPSM (Dual Paraboloid Shadow Maps). Please note we will be rendering to cubemaps, then converting to DPSM.</p>
<p>We won't be rendering directly to DPSM as testing shows it deforms too much when tessellation is low. We could support it, but it's not a priority. So <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> first needs to render to a cubemap, which can be shared by all shadow maps, and then a converter transforms it to DPSM.</p>
<p>The reason to use scene -&gt; Cubemap -&gt; DPSM is so that we keep a reasonable memory footprint and be atlas friendly. If we use cubemaps directly and want to support 8 point lights at 1024x1024, then we would have to do 1024x1024x6x8 = 192MB. However with DPSM it would be 8 DPSM and 1 cubemap: 1024x1024x4x8 + 1024x1024x4x6 = 56MB.</p>
<p>So, to setup a point light with a temporary cubemap, it goes as follows:</p>
<div class="fragment"><div class="line">abstract target cubemap_target_shadow</div>
<div class="line">{</div>
<div class="line">    pass clear { colour_value 1 1 1 1 }</div>
<div class="line">    pass render_scene</div>
<div class="line">    {</div>
<div class="line">        camera_cubemap_reorient <span class="keyword">true</span></div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="line">compositor_node_shadow PointLight</div>
<div class="line">{</div>
<div class="line">    technique pssm</div>
<div class="line"> </div>
<div class="line">    texture pointLightTex0 2048 2048 PF_D32_FLOAT no_fsaa</div>
<div class="line">    texture pointLightTex1 2048 2048 PF_D32_FLOAT no_fsaa</div>
<div class="line">    texture tmpCubemap 1024 1024 PF_FLOAT32_R cubemap no_fsaa</div>
<div class="line"> </div>
<div class="line">    technique focused</div>
<div class="line">    shadow_map 0 pointLightTex0 light 0</div>
<div class="line">    shadow_map 1 pointLightTex1 light 1</div>
<div class="line"> </div>
<div class="line">    shadow_map_target_type point</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">//shadow_map_repeat tells to repeat what&#39;s inside its body for shadow map 0 &amp; 1</span></div>
<div class="line">        shadow_map_repeat 0 1</div>
<div class="line">        {</div>
<div class="line">            <span class="comment">//Render to the cubemap with the camera settings of</span></div>
<div class="line">            <span class="comment">//the currently iterated point light shadow map</span></div>
<div class="line">            target tmpCubemap +X : cubemap_target_shadow {}</div>
<div class="line">            target tmpCubemap -X : cubemap_target_shadow {}</div>
<div class="line">            target tmpCubemap +Y : cubemap_target_shadow {}</div>
<div class="line">            target tmpCubemap -Y : cubemap_target_shadow {}</div>
<div class="line">            target tmpCubemap +Z : cubemap_target_shadow {}</div>
<div class="line">            target tmpCubemap -Z : cubemap_target_shadow {}</div>
<div class="line"> </div>
<div class="line">            <span class="comment">//Render to the current shadow map being iterated.</span></div>
<div class="line">            shadow_map</div>
<div class="line">            {</div>
<div class="line">                pass render_quad</div>
<div class="line">                {</div>
<div class="line">                    <span class="comment">//This material can be found in Samples/Media/2.0/materials/Common</span></div>
<div class="line">                    material <a class="code hl_namespace" href="namespace_ogre.html">Ogre</a>/DPSM/CubeToDpsm</div>
<div class="line">                    input 0 tmpCubemap</div>
<div class="line">                }</div>
<div class="line">            }</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="ttc" id="anamespace_ogre_html"><div class="ttname"><a href="namespace_ogre.html">Ogre</a></div><div class="ttdoc">bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;</div><div class="ttdef"><b>Definition</b> OgreAndroidLogListener.h:35</div></div>
</div><!-- fragment --><p>See Samples/Media/2.0/scripts/Compositors/ShadowMapDebugging.compositor for an example of a full script that can support directional, spot &amp; point lights all in one, in a single atlas.</p>
<h2><a class="anchor" id="CompositorShadowNodesReuseEtc"></a>
Reuse, recalculate and first</h2>
<p>Each <code>PASS_SCENE</code> from regular nodes have three settings:</p>
<ol type="1">
<li><code>SHADOW_NODE_REUSE</code></li>
<li><code>SHADOW_NODE_RECALCULATE</code></li>
<li><code>SHADOW_NODE_FIRST_ONLY</code></li>
</ol>
<p>This affect when shadow nodes are executed and how they cache their results. The default value is <code>SHADOW_NODE_FIRST_ONLY</code>; in which means <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> should manage this automatically; however there are times when <code>SHADOW_NODE_REUSE</code> could be useful.</p>
<p>It's easier to explain what they do with examples.</p>
<p>Suppose the user has two <code>render_scene</code> passes, both have the same shadow node associated:</p>
<ol type="1">
<li>One for opaque geometry.</li>
<li>Another for transparent geometry,</li>
</ol>
<p>If using <code>SHADOW_NODE_FIRST_ONLY</code>, when the first pass is executed (opaque geometry), <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> will first execute the shadow nodes, updating the shadow maps; then render the opaque geometry.</p>
<p>When the second pass is executed (transparent geometry), the shadow node won't be executed as the shadow maps are supposed to be up to date; hence the transparent geometry will reuse the results.</p>
<p>Another example: Suppose the user has three passes:</p>
<ol type="1">
<li>One for opaque geometry.</li>
<li>Another for reflections, seen from a different camera.</li>
<li>The last pass for transparent geometry, rendered using the same camera as opaque geometry.</li>
</ol>
<p>If using <code>SHADOW_NODE_FIRST_ONLY</code>; the shadow node will be executed before the opaque geometry pass.</p>
<p>Then the reflections' pass comes. It uses a different camera, which means there could be a different set of lights that will be used for shadow casting (since some techniques set shadow cameras relative to the rendering camera for optimum quality, pssm splits become obsolete, some lights are closer to this camera than they were to the player's camera, etc). <em><b><a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> has no choice but to recalculate and execute the shadow node again, updating the shadow maps</b></em>.</p>
<p>When the third pass kicks in, the camera has changed again; thus we need to execute the shadow node... again!</p>
<p><a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> will log a warning when it detects a suboptimal compositor setup such as this one. To be more specific, <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> detects that the 3rd pass uses the same results as the 1st pass, but the shadow node is being forced to recalculate in the third one, instead of reusing.</p>
<p>There are several ways to solve this problem:</p>
<ol type="1">
<li>Render reflections first: This is perhaps the most obvious one. If there are no data dependencies; first perform the reflection pass, and then the opaque &amp; transparent passes; so the shadow node is executed twice instead of three times.</li>
<li>Use two shadow nodes: When the first option isn't viable (i.e. there's a data dependency) using two shadow nodes will guarantee the results don't get overwritten. This option needs more VRAM though.</li>
<li><b>Use SHADOW_NODE_REUSE in the reflection render_scene pass:</b> This will force <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> not to execute the shadow node. This assumes you know what you're doing or else you may experience glitches (i.e. pssm splits aren't fully usable from a camera with a different position). This is useful though, if you wish to maintain consistency in the light list being used (since recalculation may cause a different set of lights to be used for shadow maps, since it depends on proximity to the active camera). Another reason to force reusage could be performance: The shadow node is only being executed once.</li>
</ol>
<p>The setting <code>SHADOW_NODE_RECALCULATE</code> forces <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> to always recalculate. <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> will not issue a warning if it detects your node setup is suboptimal because of passes using <code>SHADOW_NODE_RECALCULATE</code>.</p>
<p>Forcing recalculation only makes sense when the application makes relevant changes to the camera between passes that <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> cannot detect (i.e. change the position or the orientation through listeners)</p>
<h2><a class="anchor" id="CompositorShadowNodesTypes"></a>
Shadow mapping setup types</h2>
<p><a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> supports 5 depth shadow mapping techniques. Although they're as old as <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 1.4 or older, they've never been mentioned in the manual, and the doxygen documentation is quite cryptic, assuming the reader is quite familiar with the original papers. Here each is technique explained.</p>
<h3><a class="anchor" id="CompositorShadowNodesTypesUniform"></a>
Uniform shadow mapping</h3>
<p>The oldest form of shadow mapping, and the most simple one. It's very basic and thus probably glitch-free. However it's quality is very bad, even on high resolutions.</p>
<p>The user needs to call <code>SceneManager::setShadowDirectionalLightExtrusionDistance</code> &amp; <code>SceneManager::getShadowFarDistance</code> let <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> know how far directional lights should be from camera (since theoretically they're infinitely distant). If the value is too low, some casters won't be included and thus won't cast a shadow. Too high and the quality will quickly degrade.</p>
<p>Most likely only useful for testing that shaders are working correctly, and shadows not showing up correctly is not an <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> bug or the scene (i.e. casters with infinite aabbs can cause trouble for Focused techniques).</p>
<h3><a class="anchor" id="CompositorShadowNodesTypesFocused"></a>
Focused</h3>
<p>An improved form over uniform shadow mapping. The technique uses the AABB enclosing all casters, an AABB enclosing all receivers visible by the current camera and the camera's frustum to build a hull (which is the intersection of all three, also known as the "intersection body B"). With this hull's information, Focused shadow mapping is able to deduce the optimal extrusion distance (no need to set it like in uniform shadow mapping), and create a much tighter near and far plane, resulting in much superior quality.</p>
<p><code>SceneManager::getShadowFarDistance</code> is still used, and it can cause major quality improvements, because the camera's frustum used to build the hull is first clipped at the shadow far distance (instead of using the camera's far plane)</p>
<p>Most of the time, this is one of the best choices for general shadow mapping.</p>
<h3><a class="anchor" id="CompositorShadowNodesTypesPssm"></a>
PSSM / CSM</h3>
<p>PSSM stands for Parallel Split Shadow Mapping aka. Cascaded Shadow Maps.</p>
<p>Shadow maps are divided into "cascades" or "splits"; in order to improve quality. So instead of getting one RTT per light, the user gets multiple RTTs per light. Usually the depth in camera space is determining factor to know which cascade/split to use.</p>
<p>There's a lot of resources on internet regarding PSSM / CSM:</p>
<ul>
<li><a href="http://mynameismjp.wordpress.com/2013/09/10/shadow-maps/">A Sampling of Shadow Techniques</a></li>
<li><a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ee416307(v=vs.85).aspx">Cascaded Shadow Maps</a></li>
<li><a href="http://visual-computing.intel-research.net/art/publications/sdsm/">Sample Distribution Shadow Maps</a></li>
<li><a href="http://http.developer.nvidia.com/GPUGems3/gpugems3_ch10.html">Parallel-Split Shadow Maps on Programmable GPUs</a></li>
</ul>
<p>The original technique was introduced by Fan Zhang, Hanqiu Sun, Leilei Xu &amp; Lee Kit Lun</p>
<h3><a class="anchor" id="CompositorShadowNodesTypesPlaneOptimal"></a>
Plane Optimal</h3>
<p>TBD</p>
<h2><a class="anchor" id="CompositorShadowNodesShaders"></a>
Writing shaders</h2>
<p>Writing the necessary shaders to get depth shadow mapping work can be difficult due to the amount of factors that weight in and the flexibility that <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> offers.</p>
<p>It is often better to use a shader generator or a material system that is less flexible but allows easier setting up of shadow maps, like <a href="http://www.ogre3d.org/tikiwiki/tiki-index.php?page=RT+Shader+System">RTSS</a> or <a href="https://github.com/scrawl/shiny">Shiny</a></p>
<p>That being said, in order to make a shadow mapping shader work, the following checklist will come in handy:</p>
<ul>
<li>Written receiver's Vertex &amp; Pixel shader to use depth shadow mapping <br  />
</li>
<li>Material uses right pair of receiver vertex shader &amp; caster vertex shader <br  />
</li>
<li>Caster's vertex shader's math matches the receiver vertex shader's (i.e. skinning, instancing) <br  />
</li>
<li>VTF Instancing: The texture_unit is set to use a VTF texture for the caster. <br  />
</li>
</ul>
<p>TBD</p>
<h1><a class="anchor" id="CompositorWorkspaces"></a>
Workspaces</h1>
<p>Nodes are useless without setting up a workspace.</p>
<p>A workspace defines what nodes are going to be used and how they're going to be connected. They also need to declare global textures. <b>Declaration order is very important</b>.</p>
<p>Nodes are automatically in use when their connection is specified.</p>
<div class="fragment"><div class="line">connect &lt;Node Name 1&gt; [&lt;output ch #&gt;] [&lt;output ch #&gt;]  &lt;Node Name 2&gt; [&lt;input ch #&gt;] [&lt;input ch #&gt;]</div>
</div><!-- fragment --><p>Connects the Node "Node Name 1" output channels to "Node Name 2" input channels. This implicitly means "Node Name 1" &amp; "Node Name 2" will be used and executed by the workspace (even if they're isolated and never reach the screen)</p>
<ul>
<li>&lt;Node Name 1&gt;;</li>
</ul>
<p>The name of the Node that will be executed before "Node Name 2"</p>
<ul>
<li>[&lt;output ch #&gt;;] [&lt;output ch #&gt;;] … [&lt;output ch #&gt;;]</li>
</ul>
<p>Channel numbers from "Node Name 1"'s output channels that will be connected to "Node Name 2".</p>
<ul>
<li>&lt;Node Name 2&gt;;</li>
</ul>
<p>The name of the Node that will be executed after "Node Name 1"</p>
<ul>
<li>[&lt;input ch #&gt;;] [&lt;input ch #&gt;;] … [&lt;input ch #&gt;;]</li>
</ul>
<p>Channel numbers from "Node Name 2"'s inputs channels that will be connected from "Node Name 1" bindings.</p>
<p>Examples:</p>
<div class="fragment"><div class="line"><span class="comment">//Connect nodeA to nodeB</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 0 ==&gt; B&#39;s input channel 1</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 1 ==&gt; B&#39;s input channel 2</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 2 ==&gt; B&#39;s input channel 0</span></div>
<div class="line">connect nodeA 0 1 2 nodeB 1 2 0</div>
<div class="line"> </div>
<div class="line"><span class="comment">//Connect nodeA to nodeB</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 0 ==&gt; B&#39;s input channel 0</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 2 ==&gt; B&#39;s input channel 1</span></div>
<div class="line">connect nodeA 0 2 nodeB  0 1</div>
<div class="line"> </div>
<div class="line"><span class="comment">//Connect nodeC to nodeB</span></div>
<div class="line"><span class="comment">//C&#39;s output channel 3 ==&gt; B&#39;s input channel 1</span></div>
<div class="line">connect nodeC 3 nodeB 1</div>
</div><!-- fragment --><p>Not all output channels must be used. Take in mind that if an output is not used at all, it will still take CPU &amp; GPU processing time. MRT (Multiple Render Target) textures are designed to travel through a single channel.</p>
<blockquote class="doxtable">
<p>&zwj; Attention #1!</p>
<p>All nodes must have their input channels connected. If a node has a disconnected input channel, the workspace will fail to initialize and throw a warning.</p>
<p>Attention #2!</p>
<p>Nodes that have no input channels will be the first to be executed, regardless of declaration order (but nodes without input channels declared first should run before nodes declared later with no input channels). Take this in mind if you plan to use global textures as a means of passing information (usually a very bad idea). </p>
</blockquote>
<div class="fragment"><div class="line">connect_external &lt;external channel #&gt; &lt;Node Name&gt; &lt;input channel #&gt;</div>
</div><!-- fragment --><p>Connects the final render target (i.e. the RenderWindow) to the specified input channel from the node. Implicitly the node will be used and executed. The render target in external channel #0 is always used as the reference for target_width, target_width_scaled and all other parameters that are based on an external RTT. You can use connect_external as many times as you want. The external render targets are passed in C++ code when initializing the Workspace.</p>
<p>It is possible for a Workspace to not use this variable (though rather pointless)</p>
<ul>
<li><p class="startli">&lt;external channel #&gt;;</p>
<p class="startli">The index to the external UAV buffer passed to addWorkspace.</p>
</li>
<li>&lt;Node Name 1&gt;;</li>
</ul>
<p>The name of the Node that will receive the final RTT</p>
<ul>
<li>&lt;input channel #&gt;;</li>
</ul>
<p>The number of the input channel from "Node Name 1".</p>
<p>Example:</p>
<div class="fragment"><div class="line"><span class="comment">//Pass the external texture to nodeA through channel #0</span></div>
<div class="line">connect_external 0 nodeA 0</div>
<div class="line"><span class="comment">//Pass the external texture to nodeB through channel #0</span></div>
<div class="line">connect_external 0 nodeB 0</div>
<div class="line"><span class="comment">//Pass a second external texture to nodeB through channel #1</span></div>
<div class="line">connect_external 1 nodeB 1</div>
</div><!-- fragment --><div class="fragment"><div class="line">connect_output &lt;Node Name&gt; &lt;input channel #&gt;</div>
</div><!-- fragment --><p>It's the same as <code>connect_external 0 &lt;Node Name&gt; &lt;input channel&gt;</code>.</p>
<p>Provided for compatibility reasons and convenience. Originally only one connect_output was allowed, but now you can use it as often as you want.</p>
<div class="fragment"><div class="line">alias &lt;Node Name&gt; &lt;Aliased Name&gt;</div>
</div><!-- fragment --><p>Normally, a Node is always reused. So, if node A connects to B and C; and D connects to A; it's always the same node A the one we're talking about. The definition is only instantiated once.</p>
<p>However there may be cases where you want to have multiple instances of the same node definition (i.e. because you want unique local textures, or because you want to repeat a process on a different set of nodes), and hence that's what node aliasing does. Once an alias is declared, the node will be instantiated with a different name (its aliased name), and will be possible to make connections with it.</p>
<ul>
<li>&lt;Node Name&gt;;</li>
</ul>
<p>The name of the original instance</p>
<ul>
<li>&lt;Aliased Name&gt;;</li>
</ul>
<p>The alias name to give to this separate instance. The alias must be unique across the workspace, and must also be unique across the names of original node definitions.</p>
<p>Example:</p>
<div class="fragment"><div class="line">workspace MyWorkspace</div>
<div class="line">{</div>
<div class="line">    alias nodeA UniqueNode1     <span class="comment">//Instantiate nodeA, calling it UniqueNode1</span></div>
<div class="line"> </div>
<div class="line">    connect nodeA       0 UniqueNode1 0</div>
<div class="line">    connect nodeA       0 nodeB 0</div>
<div class="line">    connect UniqueNode1 0 nodeB 1</div>
<div class="line">}</div>
</div><!-- fragment --><div class="fragment"><div class="line">buffer &lt;buffer_name&gt; &lt;num_elements&gt; &lt;bytes_per_element&gt; [target_width] [target_width_scaled] [target_height] [target_height_scaled]</div>
</div><!-- fragment --><p>Creates an UAV buffer.</p>
<ul>
<li>&lt;buffer_name&gt;;</li>
</ul>
<p>The name of the buffer. Unlike textures, there are no naming restrictions (i.e. no <code>global_</code> prefix). If a buffer local to the node and a global buffer have the same name, the local one takes precedence and a warning is logged.</p>
<ul>
<li>&lt;num_elements&gt;;</li>
</ul>
<p>The number of elements in the UAV. Must be a number higher than 0.</p>
<ul>
<li>&lt;bytes_per_element&gt;;</li>
</ul>
<p>Bytes per element. Must be a number higher than 0.</p>
<ul>
<li>[target_width] [target_height] [target_width_scaled] [target_height_scaled]</li>
</ul>
<p>They work like their texture counterparts, and when present, will be multiplied against the number of elements.</p>
<p>The size of the UAV buffer is calculated as follows:</p>
<div class="fragment"><div class="line">finalNumElements = numElements * bytesPerElement;</div>
<div class="line"><span class="keywordflow">if</span>( widthFactor &gt; 0 )</div>
<div class="line">    finalNumElements *= (widthFactor * width);</div>
<div class="line"><span class="keywordflow">if</span>( heightFactor &gt; 0 )</div>
<div class="line">    finalNumElements *= (heightFactor * height);</div>
</div><!-- fragment --><p>For example if you want to do 512 x height; just set numElements to 512 and target_height or target_height_scaled 1.</p>
<p>Since there are no pixel formats, the bytesPerElement controls such such thing (eg. 4 bytes for RGBA8888).</p>
<p>UAV Buffers are not just for storing contiguous texture data. For example if you run a compute shader that gathers all lights, you would store the following in an UAV buffer:</p>
<div class="fragment"><div class="line"><span class="keyword">struct </span>Lights</div>
<div class="line">{</div>
<div class="line">    float3 position;</div>
<div class="line">    float3 direction;</div>
<div class="line">    float3 diffuse;</div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">RWStructuredBuffer&lt;Lights&gt; myLights;</div>
</div><!-- fragment --><p>In this case, numElements = 16 means we can address up to myLights[15]; and bytesPerElement = 36.</p>
<p>bytesPerElement must account padding according to the HLSL rules (4 x 4 x 3 =&gt;; 4 floats x sizeof(float) x 3).</p>
<p>Because calculation of bytesPerElement can get really tricky by hand (or may change dynamically at runtime), complex cases are best if the UAV is created in C++, and passed to the Workspace via connect_buffer_external.</p>
<p>Why consider UAV buffers for texture operations?</p>
<p>Regular textures have an optimized layout for adapting to most rasterization cases (filtering, stretching). Often these layout is swizzled or tiled (i.e. storing data as RRRR GGGG BBBB AAAA, or storing pixels in <a href="https://en.wikipedia.org/wiki/Z-order_curve">morton order</a>). Sometimes they may even be losslessly compressed by the GPU.</p>
<p>When you're working with compute shaders (e.g. for postprocessing) and don't need filtering, your access patterns will likely be flat, linear and contiguous, and thus get higher performance by using an UAV Buffer.</p>
<p>This is not a rule of thumb. You'll need to experiment with both UAV textures and UAV buffers in your compute shaders to see what gives you the best performance.</p>
<div class="fragment"><div class="line">connect_buffer &lt;Node Name 1&gt; [&lt;output ch #&gt;] [&lt;output ch #&gt;]  &lt;Node Name 2&gt; [&lt;input ch #&gt;] [&lt;input ch #&gt;]</div>
</div><!-- fragment --><p>Exactly the same as connect, but it connects UAV buffers instead of textures.</p>
<p>Example:</p>
<div class="fragment"><div class="line"><span class="comment">//Connect nodeA to nodeB</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 0 ==&gt; B&#39;s input channel 1</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 1 ==&gt; B&#39;s input channel 2</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 2 ==&gt; B&#39;s input channel 0</span></div>
<div class="line">connect_buffer nodeA 0 1 2 nodeB 1 2 0</div>
<div class="line"> </div>
<div class="line"><span class="comment">//Connect nodeA to nodeB</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 0 ==&gt; B&#39;s input channel 0</span></div>
<div class="line"><span class="comment">//A&#39;s output channel 2 ==&gt; B&#39;s input channel 1</span></div>
<div class="line">connect_buffer nodeA 0 2 nodeB  0 1</div>
<div class="line"> </div>
<div class="line"><span class="comment">//Connect nodeC to nodeB</span></div>
<div class="line"><span class="comment">//C&#39;s output channel 3 ==&gt; B&#39;s input channel 1</span></div>
<div class="line">connect_buffer nodeC 3 nodeB 1</div>
</div><!-- fragment --><div class="fragment"><div class="line">connect_buffer_external &lt;external channel #&gt; &lt;Node Name&gt; &lt;input channel #&gt;</div>
</div><!-- fragment --><p>Connects multiple external UAV buffer. External UAV buffers are provided when instantiating the Workspace via addWorkspace in C++.</p>
<p>It is possible for a Workspace to not use this variable (though rather pointless)</p>
<ul>
<li>&lt;external channel #&gt;;</li>
</ul>
<p>The index to the external UAV buffer passed to addWorkspace.</p>
<ul>
<li>&lt;Node Name&gt;;</li>
</ul>
<p>The name of the Node that will receive the external UAV</p>
<ul>
<li>&lt;input channel #&gt;;</li>
</ul>
<p>The number of the input channel from "Node Name".</p>
<p>Example:</p>
<div class="fragment"><div class="line"><span class="comment">//Pass the external UAV to nodeA through channel #0</span></div>
<div class="line">connect_buffer_external 0 nodeA 0</div>
<div class="line"><span class="comment">//Pass the external UAV to nodeB through channel #0</span></div>
<div class="line">connect_buffer_external 0 nodeB 0</div>
<div class="line"><span class="comment">//Pass a second external UAV to nodeB through channel #1</span></div>
<div class="line">connect_buffer_external 1 nodeB 1</div>
</div><!-- fragment --><h2><a class="anchor" id="CompositorWorkspacesDataDependencies"></a>
Data dependencies between nodes and circular dependencies</h2>
<p>The Compostor will solve data dependencies and reorder node execution as necessary. It will also detect some circular dependencies (i.e. node A connecting to A; A connecting to B and B connecting to A) report the error and refuse to initialize the workspace, but it may not detect more complex cases (i.e. node A connecting to B, B to C, C to D, D to B) and attempting execution could result in crashes or graphical glitches.</p>
<p>If you happen to encounter a circular dependency that is not reported by <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a>, we would be intereste in knowing more about it. You can <a href="https://ogre3d.atlassian.net/browse/OGRE">submit your bug report to JIRA</a></p>
<h1><a class="anchor" id="CompositorSetupCode"></a>
Setting up code</h1>
<h2><a class="anchor" id="CompositorWorkspacesSetupInitialize"></a>
Initializing the workspace</h2>
<p>To create the workspace, just call the following function with the name of the workspace:</p>
<div class="fragment"><div class="line">CompositorManager2 *compositorManager = mRoot-&gt;getCompositorManager2();</div>
<div class="line">compositorManager-&gt;addWorkspace( mSceneMgr, mWindow, mCamera, <span class="stringliteral">&quot;MyOwnWorkspace&quot;</span>, <span class="keyword">true</span> );</div>
</div><!-- fragment --><p>You can have more than one Workspace instance of the same Workspace definition. This is mostly useful if you're trying to render to two or more different RTs (i.e. two Render Windows, a RenderWindow and an offscreen RTT, etc) or if you want to use completely different SceneManagers.</p>
<h2><a class="anchor" id="CompositorWorkspacesSetupSimple"></a>
Simple bootstrap for beginners</h2>
<p>If you're a user that doesn't want to deal with compositor nodes, you're a beginner, or you're in a rush, there is an utility function that will help you set up a basic workspace and a compositor node to render the whole scene:</p>
<div class="fragment"><div class="line"><span class="keyword">const</span> IdString workspaceName( <span class="stringliteral">&quot;MyOwnWorkspace&quot;</span> );</div>
<div class="line">CompositorManager2 *compositorManager = mRoot-&gt;getCompositorManager2();</div>
<div class="line"><span class="keywordflow">if</span>( !compositorManager-&gt;hasWorkspaceDefinition( workspaceName ) )</div>
<div class="line">    compositorManager-&gt;createBasicWorkspaceDef( workspaceName, ColourValue( 0.6f, 0.0f, 0.6f ) );</div>
<div class="line">compositorManager-&gt;addWorkspace( mSceneMgr, mWindow, mCamera, workspaceName, <span class="keyword">true</span> );</div>
</div><!-- fragment --><p>The workspace created by the utility function is equivalent to the following compositor script:</p>
<div class="fragment"><div class="line">compositor_node MyOwnWorkspace_Node</div>
<div class="line">{</div>
<div class="line">    in 0 renderwindow</div>
<div class="line"> </div>
<div class="line">    target renderwindow</div>
<div class="line">    {</div>
<div class="line">        pass render_scene</div>
<div class="line">        {</div>
<div class="line">            load</div>
<div class="line">            {</div>
<div class="line">                all clear</div>
<div class="line">                clear_colour 0.6 0 0.6 1</div>
<div class="line">            }</div>
<div class="line"> </div>
<div class="line">            rq_first    0</div>
<div class="line">            rq_last     max</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">workspace MyOwnWorkspace</div>
<div class="line">{</div>
<div class="line">    connect_output MyOwnWorkspace_Node 0</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="CompositorWorkspacesSetupAdvanced"></a>
Advanced C++ users</h2>
<p>Advanced C++ users who want to deal with the <code>CompositorManager2</code> directly, may find the information in this section useful.</p>
<p>The <code>CompositorManager2</code> uses a C++ pattern where there is an object Definition and an instance. For example; there is a class called <code>CompositorPassSceneDef</code> and a class called <code>CompositorPassScene</code>. The former is the definition, while the latter is the instance.</p>
<p>All instances share the same definition and have only read-access to them. Modifying the shared definition while there are instances active is undefined and could happen anything ranging from what the user expected, to glitches, crashes, or memory leaks. Only by analyzing the code it is possible to determine which changes are likely to be "safe" (like changing the visibility mask) and which ones require the instance to be destroyed and recreated.</p>
<p>The syntax of the compositor scripts translate almost 1:1 to definitions, rather than instances. Probably the most notable difference is that <code>NodeDef</code>s contain <code>CompositorTargetDef</code>, and these contain <code>CompositorPassDef</code>; while the instances, Targets and Passes are joined together, thus Nodes contain <code>CompositorPasses</code> directly.</p>
<p>Because the <code>CompositorManager2</code> is still very new, we admit real time changes to nodes (especially channel connections) can be a bit troublesome to deal with unless destroying everything and recreating it, which could be suboptimal for live editing nodes.</p>
<p>We would love to hear your developer feedback on the <a href="http://ogre3d.org/forums/">forums</a> regarding live editing the nodes and further improve the Compositor.</p>
<h1><a class="anchor" id="StereoAndSplitScreenRendering"></a>
Stereo and Split-Screen Rendering</h1>
<p>Rendering in Stereo ala Occulus Rift™ (or splitting the screen in multiple sections for multiplayer) has been made easier with the introduction of execution and viewport masks.</p>
<p>Normally, to render to the left side of the screen and then to the right side; you would need to create a clear pass to clear the whole render target, and two passes <code>render_scene</code> passes with different viewport settings, one for each eye.</p>
<p>With execution and viewport modifier masks, you no longer need to duplicate the number of passes per region of screen you want to draw to. You will have to create a workspace for each region though (i.e. one workspace per eye).</p>
<h2><a class="anchor" id="CompositorWorkspacesStereoPerWorkspace"></a>
Per-Workspace offset and scale</h2>
<p>Each workspace contains an offset and scale to be applied to each pass; passed as a <code>Vector4</code> to <code>CompositorManager2::addWorkspace</code>. The XY components contain the offset, the ZW contain the scale.</p>
<p>On each pass, its final viewport is calculated this way:</p>
<div class="fragment"><div class="line">Real left   = mDefinition-&gt;mVpLeft      + vpModifier.x;</div>
<div class="line">Real top    = mDefinition-&gt;mVpTop       + vpModifier.y;</div>
<div class="line">Real width  = mDefinition-&gt;mVpWidth     * vpModifier.z;</div>
<div class="line">Real height = mDefinition-&gt;mVpHeight    * vpModifier.w;</div>
</div><!-- fragment --><p>This means that to render to the left eye, you would need to specify <code>Vector4( 0.0f, 0.0f, 0.5f, 1.0f )</code> and to render to the right eye you would specify <code>Vector4( 0.5f, 0.0f, 0.5f, 1.0f )</code>.</p>
<h2><a class="anchor" id="CompositorWorkspacesStereoViewportMask"></a>
Viewport modifier mask</h2>
<p>You don't want the modifier to affect <em>all</em> passes. The viewport modifer mask is a per-pass 8-bit value that is AND'ed with the workspace's mask. If the result is non-zero, the offset and scale is applied.</p>
<p>For example, you can apply postprocessing passes to entire screen instead of just a single eye.</p>
<p>The most common use for this mask is clearing: The GPU prefers that you clear the entire buffer in one go, rather than two partial clears. Therefore you can use the mask to prevent the clear's viewport from being affected, and end up affecting the whole screen.</p>
<p>There's still a problem though: You have two workspaces (one per eye). The first workspace will work as intended. However the workspace will execute the clear again, and remove the contents drawn to the left eye. The Execution Mask solves this problem.</p>
<h2><a class="anchor" id="CompositorWorkspacesStereoExecutionMask"></a>
Execution mask</h2>
<p>The execution mask is per-pass 8-bit value that is AND'ed with the workspace's execution mask. When zero, the pass is skipped, when non-zero, the pass is executed.</p>
<p>Continuing the example from the previous section, you can use an execution mask to cause the clear to only be executed when rendering the first left eye; and the clear pass will not be performed when rendering the right eye.</p>
<p>As another example, you could use two <code>render_pass</code> to perform Anaglyph 3D, i.e. red tint on the left eye, cyan tint on the right eye. You would set the viewport modifier mask to 0 so that it's not be affected by the workspace's offset and scale; but set the execution masks so that the red tint pass only gets executed for the left eye's workspace, and the cyan pass only gets executed for the right eye's workspace.</p>
<h2><a class="anchor" id="CompositorWorkspacesStereoDefaultValues"></a>
Default values</h2>
<p>By default execution and viewport masks default to <code>0xFF</code> except for Clear passes where the defaults are:</p>
<div class="fragment"><div class="line"><span class="comment">//Override so that it only gets executed on the first execution on the</span></div>
<div class="line"><span class="comment">//whole screen (i.e. clear the whole viewport during the left eye pass)</span></div>
<div class="line">mExecutionMask          = 0x01;</div>
<div class="line">mViewportModifierMask   = 0x00;</div>
</div><!-- fragment --><p>This assumes that your first workspace (i.e. the left eye / first player in split screen) sets the execution mask to 1; and the other workspaces have the first bit unset for that mask.</p>
<p>Using the defaults, the following example splits the screen in 4 for multiplayer (i.e. Mario Kart™ games and similar) or also useful for editing in 4-POV modelling application; and the clear passes will apply to the whole screen with the first workspace:</p>
<div class="fragment"><div class="line"><span class="keywordflow">for</span>( <span class="keywordtype">int</span> i=0; i&lt;4; ++i )</div>
<div class="line">{</div>
<div class="line">    Vector4 vpModifier( (i % 2) * 0.5f, (i &gt;&gt; 1) * 0.5f, 0.25f, 0.25f );</div>
<div class="line">    m_workspace[i] = mgr-&gt;addWorkspace( sceneManager, renderTarget,</div>
<div class="line">                                        playerCam[i], <span class="stringliteral">&quot;MainWorkspace&quot;</span>, <span class="keyword">true</span>,</div>
<div class="line">                                        -1, vpModifier,</div>
<div class="line">                                        (1 &lt;&lt; i), (1 &lt;&lt; i) );</div>
<div class="line">}</div>
</div><!-- fragment --><p>[^5]: starting_slot + slot = 1 + 0 = 1</p>
<p>[^6]: Note: You're allowed to keep an explicitly resolved textured dirty forever (i.e. never resolve, in case your main purpose is to always access fsaa subsamples)</p>
<h1><a class="anchor" id="autotoc_md95"></a>
Advanced MSAA</h1>
<h2><a class="anchor" id="autotoc_md96"></a>
What is MSAA?</h2>
<p>MSAA (Multisample Antialiasing) is a very common antialiasing technique.</p>
<p>It is quite common to treat MSAA like black magic: it works automatically and makes those staircase effect aka jagged edges aka aliasing disappear.</p>
<p>However there are times where we need to understand how it works, what's going on and how to control it explicitly via <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a>.</p>
<h3><a class="anchor" id="autotoc_md97"></a>
Supersampling Antialiasing (SSAA) vs MSAA</h3>
<p>It is best to explain what MSAA is by first explaining its most basic form: SSAA aka Supersampling Antialiasing.</p>
<p>SSAA is simply rasterizing at higher resolution and then using a downscale filter. Huh? What's next you ask? That's it!</p>
<p>If the original render target is 1920x1080, then SSAA 4x needs to render at 3840x2160 (1920x2 = 3840 and 1080x2 = 2160, twice the width and twice the height is 4x the area!) and then downscale back to 1920x1080 either using a simple bilinear filter or something slightly more fancy (e.g. bicubic, gaussian, etc)</p>
<p>Thus we just established that SSAA is not a complex algorithm: it's just rendering at higher resolution and then scaling down to blur each of the 4 pixels into 1, producing soft edges.</p>
<p>This operation of scaling down is known as **'Resolve'**</p>
<p>The problem with SSAA: it consumes a lot of bandwidth and processing power. 4x of everything to be exact (for 4xSSAA).</p>
<p><b>That's where MSAA comes in.</b> MSAA in is basic form looks like SSAA: the GPU needs to allocate a 3840x2160 colour target and a 3840x2160 depth buffer. Thus it stll consumes 4x more memory.</p>
<h3><a class="anchor" id="autotoc_md98"></a>
MSAA approach to the problem</h3>
<p>What's different is that MSAA assumes only triangle edges are different and need special treatment. Thus for all pixels except the ones at the border of a triangle, the GPU will only run the pixel shader <em>once</em> and broadcast the colour to all 4 pixels <em>just as if it were rendering at 1920x1080</em>. This saves 4x of colour bandwidth and 4x processing power, making it very efficient.</p>
<p>The depth however is still populated at 3840x2160.</p>
<p>Ideally only at the polygon edges the pixel shader may run <em>up to</em> 4 times.</p>
<p>The major drawbacks from MSAA are two:</p>
<ul>
<li>Performance is highly dependent on the geometry involved. A scene with lots of sharp &amp; spiky triangles will force the GPU to run the pixel shader up to 4 times very often (grass blades often trigger this worst case scenario). While a scene with smoothly-connected triangles (i.e. barely any edges) will run very fast.</li>
<li>Only geometric aliasing (e.g. polygon edges) is fixed. There are other sources of aliasing (texture, shading) which are not considered. Texture aliasing is often fixed with mipmapping though. While fixing shading aliasing is still a hot topic.</li>
</ul>
<p>The specific of how the GPU keeps the MSAA contents in memory are very vendor and device-specific. However they're often not sampling-friendly (poor cache behavior, no bilinear filtering available) therefore we often resolve the contents and work on the resolved data.</p>
<p>But there are exceptions:</p>
<ol type="1">
<li>HDR tonemapping <a href="https://mynameismjp.wordpress.com/2012/10/24/msaa-overview/">should happen before resolving</a>, otherwise aliasing effects won't go away. That means an HDR tonemap needs direct access to the MSAA contents. See our HDR sample which deals with this issue.</li>
<li>Resolving a depth buffer makes no sense. Averaging depth is meaningless. Depth is often required by postprocessing effects such as Screen Space Reflections, Depth of Field, SSAO. In order to do this, either the 1920x1080 4xMSAA depth buffer gets copied to a regular 3840x2160 texture (to make it cache- and sampling-friendly) or we pretend MSAA did not happen and just take of the values, or the minimum or maximum of each. There is no right answer and it is a very similar problem <a href="https://developer.nvidia.com/gpugems/gpugems3/part-iv-image-effects/chapter-23-high-speed-screen-particles">mixed resolution particle rendering has</a>.</li>
</ol>
<h2><a class="anchor" id="autotoc_md99"></a>
Ogre + MSAA with Implicit Resolves</h2>
<p><a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> by default uses implicit resolves. When you call:</p>
<div class="fragment"><div class="line">texture = textureGpuManager-&gt;createTexture(</div>
<div class="line">                   <span class="stringliteral">&quot;MyRtt&quot;</span>,</div>
<div class="line">                   GpuPageOutStrategy::Discard,</div>
<div class="line">                   TextureFlags::RenderToTexture,</div>
<div class="line">                   TextureTypes::Type2D );</div>
<div class="line">texture-&gt;setResolution( 1920, 1080 );</div>
<div class="line">texture-&gt;setPixelFormat( PFG_RGBA8_UNORM_SRGB );</div>
<div class="line">texture-&gt;setNumMipmaps( 1u );</div>
<div class="line">texture-&gt;setSampleDescription( SampleDescription( 4u ) ); <span class="comment">// 4x MSAA</span></div>
<div class="line">texture-&gt;scheduleTransitionTo( GpuResidency::Resident );</div>
</div><!-- fragment --><p><a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> creates two textures:</p><ol type="1">
<li>The MSAA surface. Generally you don't have direct access to it. This one occupies 1920x1080x4x4 = 31.64MB</li>
<li>The implicitly resolved texture which can be used for sampling. This one occupies 1920x1080x4 = 7.91MB</li>
</ol>
<p>StoreActions control when the texture is resolved:</p><ul>
<li>Store: Do not resolve. Useful if you have to interrupt rendering to a RenderTarget, switch to another RenderTarget, and come back to continue rendering; asuming you didn't need to sample from this texture (to fetch what has been rendered so far)</li>
<li>MultisampleResolve: Always resolve the texture once we're done rendering, and we do not care about the contents of the MSAA surface. This flag won't work on non-MSAA textures and will raise an exception. You should not continue rendering to this texture after this, unless you clear it.</li>
<li>StoreAndMultisampleResolve: Always resolve the texture once we're done rendering, and we do care about the contents of the MSAA surface. It is valid to use this flag without an MSAA texture. This flag is mostly meant for explicit-resolve textures as <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> users have no way of accessing MSAA contents. However it may be useful if you need to interrupt rendering to a RenderTarget, switch to another RenderTarget while also sampling what has been rendered so far, and then come back to continue rendering to MSAA.</li>
<li>StoreOrResolve: This is the compositor's default. It behaves like 'Store' if the texture is not MSAA. It behaves like 'MultisampleResolve' if the texture is MSAA.</li>
</ul>
<p>Implicitly resolved textures is how <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> traditionally worked before <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.2 <a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> 2.1 tried to implement this but it was very basic and often broken.</p>
<h2><a class="anchor" id="autotoc_md100"></a>
Ogre + MSAA with Explicit Resolves</h2>
<p>You need to explicitly ask for explicit resolves. When you call:</p>
<div class="fragment"><div class="line">texture = textureGpuManager-&gt;createTexture(</div>
<div class="line">                   <span class="stringliteral">&quot;MyRtt&quot;</span>,</div>
<div class="line">                   GpuPageOutStrategy::Discard,</div>
<div class="line">                   TextureFlags::RenderToTexture | TextureFlags::MsaaExplicitResolve,</div>
<div class="line">                   TextureTypes::Type2D );</div>
<div class="line">texture-&gt;setResolution( 1920, 1080 );</div>
<div class="line">texture-&gt;setPixelFormat( PFG_RGBA8_UNORM_SRGB );</div>
<div class="line">texture-&gt;setNumMipmaps( 1u );</div>
<div class="line">texture-&gt;setSampleDescription( SampleDescription( 4u ) ); <span class="comment">// 4x MSAA</span></div>
<div class="line">texture-&gt;scheduleTransitionTo( GpuResidency::Resident );</div>
</div><!-- fragment --><p><a class="el" href="namespace_ogre.html" title="bswapNN may be defined as macros in &lt;sys/endian.h&gt; or &lt;sys/bswap.h&gt;">Ogre</a> creates only one texture:</p><ol type="1">
<li>The MSAA surface. This one occupies 1920x1080x4x4 = 31.64MB</li>
</ol>
<p>Therefore:</p>
<ol type="1">
<li>Binding this texture to a shader means the shader must access it via Texture2DMS (HLSL), sampler2DMS (GLSL), and texture2d_ms (Metal)</li>
</ol>
<ol type="1">
<li>Resolving must be done manually (assuming you want to resolve at all). This means setting up the RTV on the compositor manually</li>
</ol>
<p>In compositor scripts one would have to set the rtv like this:</p>
<div class="fragment"><div class="line">compositor_node MyExplicitMsaaNode</div>
<div class="line">{</div>
<div class="line">    // This is the explicit MSAA surface</div>
<div class="line">    texture myMsaaTex   target_width target_height PFG_RGBA8_UNORM_SRGB msaa_auto explicit_resolve</div>
<div class="line">    // This is where myMsaaTex will be resolved to. It&#39;s just a regular texture</div>
<div class="line">    texture myResolvedResult    target_width target_height PFG_RGBA8_UNORM_SRGB</div>
<div class="line"> </div>
<div class="line">    // Create a custom RenderTargetView.</div>
<div class="line">    // Normally Ogre automatically generates one with the same name as the texture</div>
<div class="line">    // (We could also modify that auto-generated one by specifying &#39;rtv myMsaaTex&#39;)</div>
<div class="line">    // but we create another one to emphasize it&#39;s custom-made</div>
<div class="line">    rtv myCustomRtv</div>
<div class="line">    {</div>
<div class="line">        // Specify we want to render to myMsaaTex at slot[0] but we want to resolve to myResolvedResult</div>
<div class="line">        colour  0 myMsaaTex resolve myResolvedResult</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    target myCustomRtv</div>
<div class="line">    {</div>
<div class="line">        // Render...</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p> Now you just rendered to myMsaaTex, resolved into myResolvedResult and can have direct access to MSAA samples (by binding myMsaaTex to a material).</p>
<p>See Samples/Media/2.0/scripts/Compositors/ScreenSpaceReflections.compositor for a specific example </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="manual.html">Manual</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
